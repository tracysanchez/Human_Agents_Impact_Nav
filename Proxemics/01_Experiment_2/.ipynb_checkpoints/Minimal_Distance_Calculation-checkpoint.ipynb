{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80445b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3af110e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/TwoTeras/Resources/Agent_Coordinates_Exp2_Summary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coordinates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Volumes/TwoTeras/Resources/Agent_Coordinates_Exp2_Summary.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/TwoTeras/Resources/Agent_Coordinates_Exp2_Summary.csv'"
     ]
    }
   ],
   "source": [
    "coordinates = pd.read_csv(\"/Volumes/TwoTeras/Resources/Agent_Coordinates_Exp2_Summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98d9832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ped_id</th>\n",
       "      <th>x_coord_ped</th>\n",
       "      <th>y_coord_ped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56_Sa</td>\n",
       "      <td>-256.696716</td>\n",
       "      <td>224.165863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39_Sa</td>\n",
       "      <td>112.517273</td>\n",
       "      <td>-6.309143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19_Cma</td>\n",
       "      <td>-41.706726</td>\n",
       "      <td>142.575867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55_Sa</td>\n",
       "      <td>271.753265</td>\n",
       "      <td>191.555862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25_Cma</td>\n",
       "      <td>-122.169998</td>\n",
       "      <td>-135.090012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ped_id  x_coord_ped  y_coord_ped\n",
       "0   56_Sa  -256.696716   224.165863\n",
       "1   39_Sa   112.517273    -6.309143\n",
       "2  19_Cma   -41.706726   142.575867\n",
       "3   55_Sa   271.753265   191.555862\n",
       "4  25_Cma  -122.169998  -135.090012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7714d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach_window(data):\n",
    "    \"\"\"\n",
    "    Given the data of the participant, get a dataframe that contains information about \n",
    "    the pedestrians that the participant interacted with and the time window for each \n",
    "    of these interactions.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): The data of the participant.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A dataframe containing pedestrian ID and the time window of interaction \n",
    "                   (gaze onsets on faces).\n",
    "    \"\"\"\n",
    "    # Get the first timestamp in the data\n",
    "    first_timestamp = data['date_seconds'].min()\n",
    "\n",
    "    # Get the gazes onset\n",
    "    gaze_onset = data[data[\"events\"] == 2.0]\n",
    "    \n",
    "    # Get gazes onset on Agents\n",
    "    face_gaze_static_individual_ped = gaze_onset[gaze_onset['Collider_CategoricalN'].str.contains(r'Face', regex=True, na=False)]\n",
    "    \n",
    "    # Get each name for encountered pedestrian\n",
    "    names = face_gaze_static_individual_ped[\"names\"].tolist()\n",
    "\n",
    "    # Check if there were no interaction of the participant with static pedestrians\n",
    "    if len(face_gaze_static_individual_ped) == 0:\n",
    "        # Fill the columns of the dataframe with NaN values\n",
    "        data = {\n",
    "            'ped_id': [np.nan],\n",
    "            'w_l': [np.nan],\n",
    "            'w_u': [np.nan]\n",
    "        }\n",
    "        df_sorted = pd.DataFrame(data)\n",
    "    \n",
    "    else:\n",
    "        # Define the windows (50 seconds before and 150 seconds after)\n",
    "        window_lower = face_gaze_static_individual_ped['date_seconds'] - pd.Timedelta(seconds=50)\n",
    "        window_upper = face_gaze_static_individual_ped['date_seconds'] + pd.Timedelta(seconds=150)\n",
    "\n",
    "        # Check if any window_lower is earlier than the first timestamp in the data\n",
    "        window_lower = window_lower.apply(lambda x: max(x, first_timestamp))\n",
    "\n",
    "        # Construct a dataframe with all the important information extracted\n",
    "        d = {\n",
    "            \"ped_name\": names,\n",
    "            \"window lower\": window_lower.tolist(),\n",
    "            \"window upper\": window_upper.tolist()\n",
    "        }\n",
    "        df_summary = pd.DataFrame(d)\n",
    "\n",
    "        # Detect consecutive duplicates by creating a group indicator for consecutive pedestrian encounters\n",
    "        df_summary['t_v'] = (df_summary['ped_name'].shift() != df_summary['ped_name']).cumsum()\n",
    "\n",
    "        # Create an empty list to store the group results\n",
    "        group_results = []\n",
    "\n",
    "        # Look at each group of the same pedestrian (t_v indicates consecutive duplicates)\n",
    "        for i, group in df_summary.groupby('t_v'):\n",
    "            # Check if the time difference between consecutive duplicates is less than 50 seconds\n",
    "            group['same_range'] = (group['window lower'].diff() < pd.Timedelta(seconds=50)).eq(False).cumsum()\n",
    "\n",
    "            # Aggregate by the new grouping (same_range) to merge consecutive duplicates\n",
    "            agg_dict = {\n",
    "                # First pedestrian name in the group\n",
    "                \"ped_id\": pd.NamedAgg(column='ped_name', aggfunc='first'),\n",
    "                # Minimum 'window lower' in the group\n",
    "                \"w_l\": pd.NamedAgg(column='window lower', aggfunc='min'),\n",
    "                # Maximum 'window upper' in the group\n",
    "                \"w_u\": pd.NamedAgg(column='window upper', aggfunc='max')\n",
    "            }\n",
    "\n",
    "            # Aggregate the results for each group and append to the list\n",
    "            result = group.groupby('same_range').agg(**agg_dict)\n",
    "            group_results.append(result)\n",
    "\n",
    "        # Concatenate the results to create the final sorted dataframe\n",
    "        df_sorted = pd.concat(group_results).reset_index(drop=True)\n",
    "\n",
    "    # Return the resulting dataframe\n",
    "    return df_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b930ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_minimal_distances(df_sorted, time, data):\n",
    "    \"\"\"\n",
    "    This function calculates the minimal distances between the participant and the pedestrians they interacted with,\n",
    "    and returns a DataFrame containing the pedestrian ID, minimal distance, and the number of interactions.\n",
    "\n",
    "    Parameters:\n",
    "        df_sorted (DataFrame): Contains information about the participant and the pedestrians they interacted with.\n",
    "        time (list): The time data for the participant.\n",
    "        data (DataFrame): The position data of the participant.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Contains 'ped_id', 'minimal_distance', and 'num_interactions' for each interaction.\n",
    "    \"\"\"\n",
    "    minimal_distance = []\n",
    "    ped_ids = []\n",
    "    num_interactions = []\n",
    "\n",
    "    # If no interactions occurred\n",
    "    if pd.isna(df_sorted['ped_id'].iloc[0]):\n",
    "        return pd.DataFrame({'ped_id': [np.nan], 'minimal_distance': [np.nan], 'num_interactions': [0]})\n",
    "\n",
    "    # Retrieve key details from the sorted dataframe\n",
    "    names = df_sorted.ped_id.tolist()\n",
    "    window_lower = df_sorted.w_l.tolist()\n",
    "    window_upper = df_sorted.w_u.tolist()\n",
    "    x_ped_list = df_sorted.x_coord_ped.tolist()\n",
    "    y_ped_list = df_sorted.y_coord_ped.tolist()\n",
    "\n",
    "    for i in range(len(window_lower)):\n",
    "        ped_id = names[i]\n",
    "        w_low = window_lower[i]\n",
    "        w_up = window_upper[i]\n",
    "        x_ped = x_ped_list[i]\n",
    "        y_ped = y_ped_list[i]\n",
    "\n",
    "        # Get time window data for this pedestrian\n",
    "        ts = time[time.index(list(filter(lambda j: j > w_low, time))[0]):time.index(list(filter(lambda j: j < w_up, time))[-1]) + 1]\n",
    "        data_small = data.iloc[time.index(ts[0]):(time.index(ts[-1]) + 1)]\n",
    "\n",
    "        # Get participant's position at each time point and adjust relative to pedestrian\n",
    "        x_coordinate_par = data_small[\"playerBodyPosition.x\"]\n",
    "        y_coordinate_par = data_small[\"playerBodyPosition.z\"]\n",
    "        x = [i - x_ped for i in x_coordinate_par]\n",
    "        y = [j - y_ped for j in y_coordinate_par]\n",
    "\n",
    "        # Calculate Euclidean distance\n",
    "        distances = np.sqrt(np.array(x)**2 + np.array(y)**2)\n",
    "\n",
    "        # Filter out distances greater than 13\n",
    "        filtered_distances = distances[distances < 13]\n",
    "\n",
    "        # If there are valid distances, calculate the minimal distance\n",
    "        if len(filtered_distances) > 0:\n",
    "            min_distance = np.nanmin(filtered_distances)\n",
    "\n",
    "            # Only consider distances less than 10 as valid interactions\n",
    "            if min_distance < 10:\n",
    "                minimal_distance.append(min_distance)\n",
    "                ped_ids.append(ped_id)\n",
    "                num_interactions.append(1)\n",
    "    \n",
    "    # Create a DataFrame with the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'ped_id': ped_ids,\n",
    "        'minimal_distance': minimal_distance,\n",
    "        'num_interactions': num_interactions,\n",
    "        \n",
    "    })\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facff6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0479_2\n",
      "0479_3\n",
      "0479_5\n",
      "1754_1\n",
      "1754_2\n",
      "1754_3\n",
      "1754_4\n",
      "1754_5\n",
      "2258_1\n",
      "2258_2\n",
      "2258_3\n",
      "2258_4\n",
      "2258_5\n",
      "2361_2\n",
      "2361_3\n",
      "2361_4\n",
      "2361_5\n",
      "2693_1\n",
      "2693_2\n",
      "2693_3\n",
      "2693_4\n",
      "2693_5\n",
      "3246_1\n",
      "3246_2\n",
      "3246_3\n",
      "3246_5\n",
      "3310_1\n",
      "3310_2\n",
      "3310_3\n",
      "3310_4\n",
      "3310_5\n",
      "3572_1\n",
      "3572_2\n",
      "3572_3\n",
      "3572_4\n",
      "3976_1\n",
      "3976_2\n",
      "3976_3\n",
      "3976_4\n",
      "3976_5\n",
      "4176_1\n",
      "4176_2\n",
      "4176_3\n",
      "4176_4\n",
      "4176_5\n",
      "4796_1\n",
      "4796_2\n",
      "4796_3\n",
      "4796_4\n",
      "4796_5\n",
      "4917_1\n",
      "4917_2\n",
      "4917_3\n",
      "4917_4\n",
      "4917_5\n",
      "5238_1\n",
      "5238_2\n",
      "5238_3\n",
      "5238_4\n",
      "5531_1\n",
      "5531_3\n",
      "5531_4\n",
      "5531_5\n",
      "5741_1\n",
      "5741_2\n",
      "5741_3\n",
      "5741_4\n",
      "5741_5\n",
      "6642_1\n",
      "6642_2\n",
      "6642_3\n",
      "6642_4\n",
      "6642_5\n",
      "7093_1\n",
      "7093_2\n",
      "7093_3\n",
      "7093_4\n",
      "7093_5\n",
      "7264_1\n",
      "7264_2\n",
      "7264_3\n",
      "7264_4\n",
      "7264_5\n",
      "7412_1\n",
      "7412_2\n",
      "7412_3\n",
      "7412_4\n",
      "7412_5\n",
      "7842_1\n",
      "7842_2\n",
      "7842_3\n",
      "7842_4\n",
      "7842_5\n",
      "8007_1\n",
      "8007_2\n",
      "8007_3\n",
      "8007_4\n",
      "8007_5\n",
      "8469_1\n",
      "8469_2\n",
      "8469_3\n",
      "8469_4\n",
      "8469_5\n",
      "8673_1\n",
      "8673_2\n",
      "8673_3\n",
      "8673_4\n",
      "8673_5\n",
      "8695_2\n",
      "8695_3\n",
      "8695_4\n",
      "8695_5\n",
      "9472_1\n",
      "9472_2\n",
      "9472_3\n",
      "9472_4\n",
      "9472_5\n",
      "9502_1\n",
      "9502_2\n",
      "9502_3\n",
      "9502_5\n",
      "9601_1\n",
      "9601_2\n",
      "9601_3\n",
      "9601_4\n",
      "9601_5\n",
      "0479_1\n",
      "0365_1\n",
      "0365_2\n",
      "0365_3\n",
      "0365_4\n",
      "0365_5\n",
      "2361_1\n",
      "3246_4\n",
      "4597_1\n",
      "4597_2\n",
      "4597_3\n",
      "4597_4\n",
      "4597_5\n",
      "9502_4\n",
      "9586_1\n",
      "9586_2\n",
      "9586_3\n",
      "9586_4\n",
      "9586_5\n",
      "Failures logged for 5 files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Your path\n",
    "path = \"/Volumes/TwoTeras/0_Experiment_1/Eye_Tracking/Pre_processed/05_Debbies_gaze\" \n",
    "\n",
    "# Load all CSV files in the path\n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# Create a list to store failed files and their errors\n",
    "failed_files = []\n",
    "\n",
    "# Loop through all files\n",
    "for filename in files:\n",
    "    try:\n",
    "        # Read the participant data\n",
    "        One_participant = pd.read_csv(filename)\n",
    "        One_participant = One_participant.loc[:, One_participant.columns[One_participant.columns.get_loc('SubjectID'):]]\n",
    "\n",
    "        # Convert the 'timeStampDataPointEnd' to datetime, specifying it's in seconds since epoch\n",
    "        One_participant['date_seconds'] = pd.to_datetime(One_participant['timeStampDataPointEnd'], unit='s')\n",
    "        time = One_participant['date_seconds'].tolist()\n",
    "\n",
    "        # Apply the window function to get all agent interactions\n",
    "        Windows = approach_window(One_participant)\n",
    "\n",
    "        # Check if Windows is empty and handle accordingly\n",
    "        if Windows.empty:\n",
    "            print(f\"No interactions for {filename[-10:-4]}, skipping.\")\n",
    "            continue  # Skip to the next file if no interactions\n",
    "\n",
    "        print(filename[-10:-4])\n",
    "\n",
    "        # Convert 'ped_id' in both DataFrames to strings before merging\n",
    "        Windows['ped_id'] = Windows['ped_id'].astype(str)\n",
    "        coordinates['ped_id'] = coordinates['ped_id'].astype(str)\n",
    "\n",
    "        # Perform a left merge on 'ped_id' to add 'x_coord_ped' and 'y_coord_ped' to Windows\n",
    "        merged_df = Windows.merge(coordinates, on='ped_id', how='left')\n",
    "\n",
    "        # Save the merged data to a CSV\n",
    "        merged_df.to_csv(f\"/Volumes/TwoTeras/0_Experiment_1/Proxemics/Windows_Faces/{filename[-10:-4]}.csv\", index=True)\n",
    "\n",
    "        # Calculate Minimal Distance Participant-wise\n",
    "        Minimal_Distance = calculate_minimal_distances(merged_df, time, One_participant)\n",
    "        Minimal_Distance[\"SubjectID\"] = filename[-10:-6]\n",
    "        Minimal_Distance[\"Session\"] = filename[-5]\n",
    "\n",
    "        # Save the minimal distance data to a CSV\n",
    "        Minimal_Distance.to_csv(f\"/Volumes/TwoTeras/0_Experiment_1/Proxemics/Minimal_Distance_Faces/{filename[-10:-4]}.csv\", index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        # If an error occurs, add the filename and the error message to the list\n",
    "        failed_files.append({'filename': filename[-10:-4], 'error': str(e)})\n",
    "\n",
    "# After the loop, create a DataFrame from the failed files list\n",
    "if failed_files:\n",
    "    failed_df = pd.DataFrame(failed_files)\n",
    "\n",
    "    # Save the DataFrame to a CSV file for reference\n",
    "    failed_df.to_csv(\"/Volumes/TwoTeras/0_Experiment_1/Proxemics/failed_files_log.csv\", index=False)\n",
    "\n",
    "    print(f\"Failures logged for {len(failed_files)} files.\")\n",
    "else:\n",
    "    print(\"No failures detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2412f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Volumes/TwoTeras/0_Experiment_1/Eye_Tracking/Pre_processed/05_Debbies_gaze/0365_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94827ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the old indexes \n",
    "df = data.loc[:, data.columns[data.columns.get_loc('SubjectID'):]]\n",
    "# Convert the 'timeStampDataPointEnd' to datetime, specifying it's in seconds since epoch\n",
    "df['date_seconds'] = pd.to_datetime(df['timeStampDataPointEnd'], unit='s')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e753bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Collider_CategoricalN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34099ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform a left merge on 'ped_id' to add 'x_coord_ped' and 'y_coord_ped' to df2\n",
    "merged_df = Windows.merge(coordinates, on='ped_id', how='left')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808f6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Windows.shape)\n",
    "display(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cec5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the social and personal space\n",
    "        circle2 = plt.Circle((0, 0), 1.22, color='#EE7718', edgecolor='#FAB87C', alpha=0.75)\n",
    "        circle1 = plt.Circle((0, 0), 3.65, color='#FAB87C', alpha=0.55, linewidth=1)\n",
    "        ax.add_patch(circle1)\n",
    "        ax.add_patch(circle2)\n",
    "        # plotting the zero lines in black\n",
    "        plt.axhline(color='black', lw=0.5)\n",
    "        plt.axvline(color='black', lw=0.5)\n",
    "        # labeling the x and y axis\n",
    "        plt.xlabel(\"x\", size = 20)\n",
    "        plt.ylabel(\"z\", size = 20)\n",
    "        # axis limits\n",
    "        plt.xlim(-9, +9)\n",
    "        plt.ylim(-9, +9)\n",
    "        # axis ticks size\n",
    "        plt.xticks(size=20)\n",
    "        plt.yticks(size=20)\n",
    "        # adjusting the padding of the trajectory map plot\n",
    "        plt.subplots_adjust(right=0.7)\n",
    "        plt.tight_layout(pad = 1, rect= (0.5,0.5,0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Given the dataframe that contains all encountered pedestrian for each participant , their location and time window\n",
    "of interaction, the time data and the data of each participant (df_sorted), draw the trajectory map which depict the\n",
    "pathway around each pedestrian interacted with, get this pedestrian identification number and calculate the minimum\n",
    "distance of this pathway, get the number of interactions of the participant with static individual pedestrians.\n",
    "Parameters: df_sorted which contain information about the participant and the pedestrians they interacted with, the\n",
    "time data and the data of the participant.\n",
    "Returns: The number of interaction of the participant with static indivdual pedestrians, a list of the minimum distances\n",
    "of the different interactions and a list of \"names\" of the pedestrians the participant interacted with. \"\"\"\n",
    "def get_trajectory_map_and_minimal_distance(df_sorted, time, data):\n",
    "    minimal_distance = []\n",
    "    names_in = []\n",
    "    df_for_all_ped = []\n",
    "    # check if there were interactions with pedestrians\n",
    "    if pd.isna(df_sorted['ped_id'].iloc[0]):\n",
    "        # if none the number of interaction is 0\n",
    "        number_of_interactions = 0\n",
    "        # Create an empty DataFrame with the same columns and column names\n",
    "        data = {\n",
    "            'ped_id': [np.nan],\n",
    "            'x': [np.nan],\n",
    "            'y': [np.nan]}\n",
    "\n",
    "        df_plot_result = pd.DataFrame(data)\n",
    "        # creating an empty map plot for no interactions\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8 ,8), dpi=140)\n",
    "        # plotting the social and personal space\n",
    "        circle2 = plt.Circle((0, 0), 1.22, color='#EE7718', edgecolor='#FAB87C', alpha=0.75)\n",
    "        circle1 = plt.Circle((0, 0), 3.65, color='#FAB87C', alpha=0.55, linewidth=1)\n",
    "        # zooming in on the map\n",
    "        ax.set_xlim(-10, 10)\n",
    "        ax.set_ylim(-10, 10)\n",
    "        plt.axhline(color='black', lw=0.5)\n",
    "        plt.axvline(color='black', lw=0.5)\n",
    "        ax.add_patch(circle1)\n",
    "        ax.add_patch(circle2)\n",
    "        plt.subplots_adjust(right=0.95)\n",
    "        plt.tight_layout(pad=0.8, rect=(0.5, 0.5, 0.5, 0.5))\n",
    "        minimal_distance.append(np.nan)\n",
    "        names_in.append(np.nan)\n",
    "\n",
    "    # if there are interactions\n",
    "    else:\n",
    "        # get the list of names of the encountered pedestrians\n",
    "        names = df_sorted.ped_id.tolist()\n",
    "        # get the list of lower window values in the time window for each pedestrian\n",
    "        window_lower = df_sorted.w_l.tolist()\n",
    "        # get the list of upper window values in the time window for each pedestrian\n",
    "        window_upper = df_sorted.w_u.tolist()\n",
    "        # get the list of the x coordinates for each pedestrian\n",
    "        x_ped_list = df_sorted.x_coord_ped.tolist()\n",
    "        # get the list of the y coordinates for each pedestrian\n",
    "        y_ped_list = df_sorted.y_coord_ped.tolist()\n",
    "        # plot the pathway for each pedestrian accordingly\n",
    "\n",
    "        # create a figure\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8,8), dpi = 140)\n",
    "        # get the name, location and window range around each pedestrian\n",
    "        for i in range(len(window_lower)):\n",
    "\n",
    "            ped_id = names[i]\n",
    "            w_low = window_lower[i]\n",
    "            w_up = window_upper[i]\n",
    "            x_ped = x_ped_list[i]\n",
    "            y_ped = y_ped_list[i]\n",
    "\n",
    "            # get the time window data\n",
    "            ts = time[time.index(list(filter(lambda j: j > w_low, time))[0]):time.index(list(filter(lambda j: j < w_up, time))[-1]) + 1]\n",
    "            data_small = (data.iloc[time.index(ts[0]):(time.index(ts[-1]) + 1)])\n",
    "            # get the participant location at each time point\n",
    "            x_coordinate_par = data_small[\"playerBodyPosition.x\"]\n",
    "            y_coordinate_par = data_small[\"playerBodyPosition.z\"]\n",
    "            # get x,y location of participant (taking into account ped location is (0,0) always)\n",
    "            x = [i - x_ped for i in x_coordinate_par]\n",
    "            y = [j - y_ped for j in y_coordinate_par]\n",
    "            # create data frame with the coordinates pathway around each participant\n",
    "            m = {\"ped_id\": ped_id, \"x\": x, \"y\": y}\n",
    "            df_plot = pd.DataFrame(m)\n",
    "            # calculate the Euclidean distance for each pathway around each pedestrian\n",
    "            distance = ((df_plot[\"y\"]) ** 2 + (df_plot[\"x\"]) ** 2) ** 0.5\n",
    "            # insert the calculated  distances in the df_plot\n",
    "            df_plot.insert(column=\"distance\", value=distance, loc=3)\n",
    "            # filter out any  distance that is greater than 13\n",
    "            df_plot = df_plot[df_plot.distance < 13]\n",
    "            # create a list of the filtered distances that remained\n",
    "            distance_df = df_plot.distance.tolist()\n",
    "            # get the list of the pedestrian names\n",
    "            name_1 = df_plot[\"ped_id\"].tolist()\n",
    "\n",
    "            # check if the list of distances not empty\n",
    "            if len(distance_df) != 0:\n",
    "                #calculate the minimum distance of the pathway\n",
    "                min_distance = np.nanmin(distance_df)\n",
    "\n",
    "                # only consider the minimum distances less than 10 as an interaction\n",
    "                if min_distance < 10:\n",
    "                    name_to_insert = name_1[0]\n",
    "                    names_in.append(name_to_insert)\n",
    "                    minimal_distance.append(min_distance)\n",
    "\n",
    "                # list to save the collected data if each pedestrian encountered\n",
    "                df_for_all_ped.append(df_plot)\n",
    "                # the resulting dataframe includes all encountered pedestrian data\n",
    "                df_plot_result = pd.concat(df_for_all_ped)\n",
    "                # the palette color grey\n",
    "                palette = sns.color_palette(['gray'])\n",
    "                # Plotting the trajectory map for each participant\n",
    "                ax = sns.scatterplot(data=df_plot_result, x='x', y='y', alpha=0.05, hue='ped_id', palette= palette, linewidths = 0.1, legend = False)\n",
    "\n",
    "        # get the number of interactions for each participant\n",
    "        number_of_interactions = len(names_in)\n",
    "\n",
    "        # title and axes organization of the trajectory map plot\n",
    "\n",
    "        # plotting the social and personal space\n",
    "        circle2 = plt.Circle((0, 0), 1.22, color='#EE7718', edgecolor='#FAB87C', alpha=0.75)\n",
    "        circle1 = plt.Circle((0, 0), 3.65, color='#FAB87C', alpha=0.55, linewidth=1)\n",
    "        ax.add_patch(circle1)\n",
    "        ax.add_patch(circle2)\n",
    "        # plotting the zero lines in black\n",
    "        plt.axhline(color='black', lw=0.5)\n",
    "        plt.axvline(color='black', lw=0.5)\n",
    "        # labeling the x and y axis\n",
    "        plt.xlabel(\"x\", size = 20)\n",
    "        plt.ylabel(\"z\", size = 20)\n",
    "        # axis limits\n",
    "        plt.xlim(-9, +9)\n",
    "        plt.ylim(-9, +9)\n",
    "        # axis ticks size\n",
    "        plt.xticks(size=20)\n",
    "        plt.yticks(size=20)\n",
    "        # adjusting the padding of the trajectory map plot\n",
    "        plt.subplots_adjust(right=0.7)\n",
    "        plt.tight_layout(pad = 1, rect= (0.5,0.5,0.5,0.5))\n",
    "        # showing the map\n",
    "       # plt.show()\n",
    "\n",
    "    return number_of_interactions,minimal_distance, names_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_map_and_minimal_distance(df_sorted, time, data):\n",
    "    \"\"\"\n",
    "    Given the dataframe that contains all encountered pedestrians for each participant, their location, \n",
    "    and time window of interaction, this function draws the trajectory map depicting the pathway around \n",
    "    each pedestrian, gets the pedestrian ID, and calculates the minimum distance of this pathway.\n",
    "    \n",
    "    Parameters:\n",
    "        df_sorted (DataFrame): Contains information about participants and the pedestrians they interacted with.\n",
    "        time (list): The time data for the participant.\n",
    "        data (DataFrame): The position data of the participant.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Number of interactions, list of minimum distances, and list of pedestrian names interacted with.\n",
    "    \"\"\"\n",
    "    minimal_distance = []\n",
    "    names_in = []\n",
    "    df_for_all_ped = []\n",
    "\n",
    "    # If no interactions occurred\n",
    "    if pd.isna(df_sorted['ped_id'].iloc[0]):\n",
    "        number_of_interactions = 0\n",
    "        data_empty = {\n",
    "            'ped_id': [np.nan],\n",
    "            'x': [np.nan],\n",
    "            'y': [np.nan]\n",
    "        }\n",
    "        df_plot_result = pd.DataFrame(data_empty)\n",
    "        minimal_distance.append(np.nan)\n",
    "        names_in.append(np.nan)\n",
    "    else:\n",
    "        # Retrieve key details from the sorted dataframe\n",
    "        names = df_sorted.ped_id.tolist()\n",
    "        window_lower = df_sorted.w_l.tolist()\n",
    "        window_upper = df_sorted.w_u.tolist()\n",
    "        x_ped_list = df_sorted.x_coord_ped.tolist()\n",
    "        y_ped_list = df_sorted.y_coord_ped.tolist()\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 8), dpi=140)\n",
    "\n",
    "        for i in range(len(window_lower)):\n",
    "            ped_id = names[i]\n",
    "            w_low = window_lower[i]\n",
    "            w_up = window_upper[i]\n",
    "            x_ped = x_ped_list[i]\n",
    "            y_ped = y_ped_list[i]\n",
    "\n",
    "            # Get time window data for this pedestrian\n",
    "            ts = time[time.index(list(filter(lambda j: j > w_low, time))[0]):time.index(list(filter(lambda j: j < w_up, time))[-1]) + 1]\n",
    "            data_small = data.iloc[time.index(ts[0]):(time.index(ts[-1]) + 1)]\n",
    "\n",
    "            # Get participant's position for each time point and adjust relative to pedestrian\n",
    "            x_coordinate_par = data_small[\"playerBodyPosition.x\"]\n",
    "            y_coordinate_par = data_small[\"playerBodyPosition.z\"]\n",
    "            x = [i - x_ped for i in x_coordinate_par]\n",
    "            y = [j - y_ped for j in y_coordinate_par]\n",
    "\n",
    "            # Create a dataframe for plotting and distance calculations\n",
    "            df_plot = pd.DataFrame({\"ped_id\": ped_id, \"x\": x, \"y\": y})\n",
    "            df_plot['distance'] = np.sqrt(df_plot['x']**2 + df_plot['y']**2)\n",
    "\n",
    "            # Filter out distances greater than 13\n",
    "            df_plot = df_plot[df_plot['distance'] < 13]\n",
    "            distance_df = df_plot['distance'].tolist()\n",
    "\n",
    "            if distance_df:\n",
    "                min_distance = np.nanmin(distance_df)\n",
    "\n",
    "                # Only consider distances less than 10 as valid interactions\n",
    "                if min_distance < 10:\n",
    "                    names_in.append(ped_id)\n",
    "                    minimal_distance.append(min_distance)\n",
    "\n",
    "                # Save the data for plotting\n",
    "                df_for_all_ped.append(df_plot)\n",
    "                df_plot_result = pd.concat(df_for_all_ped, ignore_index=True)\n",
    "\n",
    "        # Plot the trajectory if there are valid interactions\n",
    "        if not df_plot_result.empty:\n",
    "            sns.scatterplot(data=df_plot_result, x='x', y='y', alpha=0.05, hue='ped_id', palette=['gray'], linewidth=0.1, legend=False)\n",
    "\n",
    "        number_of_interactions = len(names_in)\n",
    "\n",
    "    # Plot the social and personal space\n",
    "    circle2 = plt.Circle((0, 0), 1.22, color='#EE7718', edgecolor='#FAB87C', alpha=0.75)\n",
    "    circle1 = plt.Circle((0, 0), 3.65, color='#FAB87C', alpha=0.55, linewidth=1)\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "\n",
    "    # Plot axis settings\n",
    "    plt.axhline(color='black', lw=0.5)\n",
    "    plt.axvline(color='black', lw=0.5)\n",
    "    plt.xlabel(\"x\", size=20)\n",
    "    plt.ylabel(\"z\", size=20)\n",
    "    plt.xlim(-9, 9)\n",
    "    plt.ylim(-9, 9)\n",
    "    plt.xticks(size=20)\n",
    "    plt.yticks(size=20)\n",
    "    plt.subplots_adjust(right=0.7)\n",
    "    plt.tight_layout(pad=1, rect=(0.5, 0.5, 0.5, 0.5))\n",
    "\n",
    "    return number_of_interactions, minimal_distance, names_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594eb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfce84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_minimal_distances(merged_df, time, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df['date_seconds'].to_list()\n",
    "get_trajectory_map_and_minimal_distance(merged_df, time, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_map_and_minimal_distance_category(df_sorted, time, data):\n",
    "    \"\"\"\n",
    "    Given the dataframe that contains all encountered pedestrians for each participant, their location, \n",
    "    and time window of interaction, this function draws separate trajectory maps for 'Cma' and 'Sa' pedestrians, \n",
    "    calculates the minimum distance of this pathway, and returns interaction details.\n",
    "    \n",
    "    Parameters:\n",
    "        df_sorted (DataFrame): Contains information about participants and the pedestrians they interacted with.\n",
    "        time (list): The time data for the participant.\n",
    "        data (DataFrame): The position data of the participant.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Number of interactions, list of minimum distances, and list of pedestrian names interacted with.\n",
    "    \"\"\"\n",
    "    minimal_distance = []\n",
    "    names_in = []\n",
    "    df_for_all_ped_cma = []\n",
    "    df_for_all_ped_sa = []\n",
    "\n",
    "    # If no interactions occurred\n",
    "    if pd.isna(df_sorted['ped_id'].iloc[0]):\n",
    "        number_of_interactions = 0\n",
    "        minimal_distance.append(np.nan)\n",
    "        names_in.append(np.nan)\n",
    "    else:\n",
    "        # Retrieve key details from the sorted dataframe\n",
    "        names = df_sorted.ped_id.tolist()\n",
    "        window_lower = df_sorted.w_l.tolist()\n",
    "        window_upper = df_sorted.w_u.tolist()\n",
    "        x_ped_list = df_sorted.x_coord_ped.tolist()\n",
    "        y_ped_list = df_sorted.y_coord_ped.tolist()\n",
    "\n",
    "        for i in range(len(window_lower)):\n",
    "            ped_id = names[i]\n",
    "            w_low = window_lower[i]\n",
    "            w_up = window_upper[i]\n",
    "            x_ped = x_ped_list[i]\n",
    "            y_ped = y_ped_list[i]\n",
    "\n",
    "            # Get time window data for this pedestrian\n",
    "            ts = time[time.index(list(filter(lambda j: j > w_low, time))[0]):time.index(list(filter(lambda j: j < w_up, time))[-1]) + 1]\n",
    "            data_small = data.iloc[time.index(ts[0]):(time.index(ts[-1]) + 1)]\n",
    "\n",
    "            # Get participant's position for each time point and adjust relative to pedestrian\n",
    "            x_coordinate_par = data_small[\"playerBodyPosition.x\"]\n",
    "            y_coordinate_par = data_small[\"playerBodyPosition.z\"]\n",
    "            x = [i - x_ped for i in x_coordinate_par]\n",
    "            y = [j - y_ped for j in y_coordinate_par]\n",
    "\n",
    "            # Create a dataframe for plotting and distance calculations\n",
    "            df_plot = pd.DataFrame({\"ped_id\": ped_id, \"x\": x, \"y\": y})\n",
    "            df_plot['distance'] = np.sqrt(df_plot['x']**2 + df_plot['y']**2)\n",
    "\n",
    "            # Filter out distances greater than 13\n",
    "            df_plot = df_plot[df_plot['distance'] < 13]\n",
    "            distance_df = df_plot['distance'].tolist()\n",
    "\n",
    "            if distance_df:\n",
    "                min_distance = np.nanmin(distance_df)\n",
    "\n",
    "                # Only consider distances less than 10 as valid interactions\n",
    "                if min_distance < 10:\n",
    "                    names_in.append(ped_id)\n",
    "                    minimal_distance.append(min_distance)\n",
    "\n",
    "                # Separate into 'Sa' and 'Cma' groups\n",
    "                if ped_id.endswith('_Sa'):\n",
    "                    df_for_all_ped_sa.append(df_plot)\n",
    "                elif ped_id.endswith('_Cma'):\n",
    "                    df_for_all_ped_cma.append(df_plot)\n",
    "\n",
    "    # Plot side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), dpi=140)\n",
    "\n",
    "    # Plot for 'Sa' pedestrians\n",
    "    if df_for_all_ped_sa:\n",
    "        df_plot_sa = pd.concat(df_for_all_ped_sa, ignore_index=True)\n",
    "        sns.scatterplot(data=df_plot_sa, x='x', y='y', alpha=0.05, hue='ped_id', palette=['gray'], linewidth=0.1, legend=False, ax=ax1)\n",
    "        ax1.set_title(\"Trajectory for Passive Agents\")\n",
    "        circle1 = plt.Circle((0, 0), 1.22, color='#FF6347', edgecolor='#FAB87C', alpha=0.75)  # Center circle in 'tomato' for 'Sa'\n",
    "        circle2 = plt.Circle((0, 0), 3.65, color='#FFA07A', alpha=0.55, linewidth=1)         # Larger circle in 'light salmon' for 'Sa'\n",
    "        ax1.add_patch(circle1)\n",
    "        ax1.add_patch(circle2)\n",
    "        ax1.axhline(color='black', lw=0.5)\n",
    "        ax1.axvline(color='black', lw=0.5)\n",
    "        ax1.set_xlim(-9, 9)\n",
    "        ax1.set_ylim(-9, 9)\n",
    "        ax1.set_xlabel(\"x\", size=20)\n",
    "        ax1.set_ylabel(\"z\", size=20)\n",
    "        ax1.tick_params(axis='both', labelsize=15)\n",
    "\n",
    "    # Plot for 'Cma' pedestrians\n",
    "    if df_for_all_ped_cma:\n",
    "        df_plot_cma = pd.concat(df_for_all_ped_cma, ignore_index=True)\n",
    "        sns.scatterplot(data=df_plot_cma, x='x', y='y', alpha=0.05, hue='ped_id', palette=['gray'], linewidth=0.1, legend=False, ax=ax2)\n",
    "        ax2.set_title(\"Trajectory for Active Agents\")\n",
    "        circle1 = plt.Circle((0, 0), 1.22, color='#1E90FF', edgecolor='#87CEEB', alpha=0.75)  # Center circle in 'dodgerblue' for 'Cma'\n",
    "        circle2 = plt.Circle((0, 0), 3.65, color='#B0E0E6', alpha=0.55, linewidth=1)         # Larger circle in 'powderblue' for 'Cma'\n",
    "        ax2.add_patch(circle1)\n",
    "        ax2.add_patch(circle2)\n",
    "        ax2.axhline(color='black', lw=0.5)\n",
    "        ax2.axvline(color='black', lw=0.5)\n",
    "        ax2.set_xlim(-9, 9)\n",
    "        ax2.set_ylim(-9, 9)\n",
    "        ax2.set_xlabel(\"x\", size=20)\n",
    "        ax2.set_ylabel(\"z\", size=20)\n",
    "        ax2.tick_params(axis='both', labelsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    number_of_interactions = len(names_in)\n",
    "    return number_of_interactions, minimal_distance, names_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56fade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df['date_seconds'].to_list()\n",
    "get_trajectory_map_and_minimal_distance_category(merged_df, time, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b90393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

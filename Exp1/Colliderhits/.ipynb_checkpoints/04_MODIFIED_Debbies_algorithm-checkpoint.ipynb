{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71bfb75a-c476-434a-8bf4-9d69cd4feada",
   "metadata": {},
   "source": [
    "# Calculate angles and velocities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4edac8-e22a-4062-86eb-3a4fa091d456",
   "metadata": {},
   "source": [
    "Eucledian_distance.rename(columns={\"Continuous_Time\": \"time\", \n",
    "                                   \"eyePositionCombinedWorld.x\": \"xcoord_orig\", \n",
    "                                   \"eyePositionCombinedWorld.z\": \"zcoord_orig\", \n",
    "                                   \"eyePositionCombinedWorld.y\": \"ycoord_orig\", \n",
    "                                   \"hitPointOnObject_x\": \"xhpoo\", \n",
    "                                   \"hitPointOnObject_y\": \"yhpoo\", \n",
    "                                   \"hitPointOnObject_z\": \"zhpoo\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21b5102-f4de-4903-9fdd-cba54e1cc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math \n",
    "from collections import Counter \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a86316a-ac82-44fe-9b0b-25f70a8f829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the collider names are too detailed, here we create a dictionary with patterns to classify them into our categories of interest\n",
    "\n",
    "patterns = {'\\d{2}_Sa':'Passive_Agent', '\\d{2}_Cma':'Active_Agent', 'Building_\\d+': 'Building'}\n",
    "patterns.update(dict.fromkeys(['Castle-TaskBuilding_56', 'Crane_59','HighSilo-TaskBuilding_49', 'Windmill-TaskBuilding_10_1', 'Church-TaskBuilding_16'], 'Global_Landmark'))\n",
    "patterns.update(dict.fromkeys(['^TaskBuilding_2$','^TaskBuilding_3$', '^TaskBuilding_5$', '^TaskBuilding_8$', '^TaskBuilding_9$', '^TaskBuilding_11$', '^TaskBuilding_13$', '^TaskBuilding_14$', '^TaskBuilding_20$', \n",
    "                               '^TaskBuilding_21$', '^TaskBuilding_23$','^TaskBuilding_27$', '^TaskBuilding_29$', '^TaskBuilding_32$', '^TaskBuilding_34$',  '^TaskBuilding_38$', '^TaskBuilding_41$', '^TaskBuilding_42$', \n",
    "                               '^TaskBuilding_44$', '^TaskBuilding_45$', '^TaskBuilding_47$', '^TaskBuilding_50$', '^TaskBuilding_51$', '^TaskBuilding_52$', 'BasketballCourt_58', 'Construction_57', \n",
    "                               '^Graffity_02$', '^Graffity_03$', '^Graffity_05$', '^Graffity_08$', '^Graffity_09$', '^Graffity_11$', '^Graffity_13$', '^Graffity_14$', '^Graffity_20$', \n",
    "                               '^Graffity_21$', '^Graffity_23$', '^Graffity_27$', '^Graffity_29$', '^Graffity_32$', '^Graffity_34$', '^Graffity_38$', '^Graffity_41$', '^Graffity_42$', \n",
    "                               '^Graffity_44$', '^Graffity_45$', '^Graffity_47$',  '^Graffity_50$', '^Graffity_51$', '^Graffity_52$'], 'TaskBuilding_Public'))\n",
    "\n",
    "patterns.update(dict.fromkeys(['^TaskBuilding_1$','^TaskBuilding_4$', '^TaskBuilding_6$', '^TaskBuilding_7$', '^TaskBuilding_12$', '^TaskBuilding_15$', '^TaskBuilding_17$', '^TaskBuilding_18$', '^TaskBuilding_19$', \n",
    "                               '^TaskBuilding_22$', '^TaskBuilding_24$','^TaskBuilding_25$', '^TaskBuilding_26$', '^TaskBuilding_28$', '^TaskBuilding_30$',  '^TaskBuilding_31$', '^TaskBuilding_33$', '^TaskBuilding_35$', \n",
    "                               '^TaskBuilding_36$', '^TaskBuilding_37$', '^TaskBuilding_39$', '^TaskBuilding_40$', '^TaskBuilding_43$', '^TaskBuilding_48$', '^TaskBuilding_54$','^TaskBuilding_55$',\n",
    "                               '^Graffity_01$','^Graffity_04$', '^Graffity_06$', '^Graffity_07$', '^Graffity_12$', '^Graffity_15$', '^Graffity_17$', '^Graffity_18$', '^Graffity_19$', '^Graffity_22$', \n",
    "                               '^Graffity_24$','^Graffity_25$', '^Graffity_26$', '^Graffity_28$', '^Graffity_30$',  '^Graffity_31$', '^Graffity_33$', '^Graffity_35$', '^Graffity_36$', '^Graffity_37$', '^Graffity_39$', \n",
    "                               '^Graffity_40$', '^Graffity_43$', '^Graffity_48$', '^Graffity_54$', '^Graffity_55$' ], 'TaskBuilding_Residential'))\n",
    "default_val = 'Background'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b57a0a6-5fb4-468c-ab0a-5f6e29a5ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: calculate MAD saccade\n",
    "def at_mad(angular_vel, th_0=200):\n",
    "    # defines the saccade threshold (code from Ashima)\n",
    "    threshs = []\n",
    "    while True:\n",
    "        # take th_0\n",
    "        threshs.append(th_0)\n",
    "        # get all angles smaller than this\n",
    "        angular_vel = angular_vel[angular_vel < th_0]\n",
    "\n",
    "        # MAD:\n",
    "        # take the median of all angles smaller than th_0\n",
    "        median = np.median(angular_vel)\n",
    "        # substract the median value\n",
    "        diff = np.sqrt((angular_vel - median) ** 2)\n",
    "        # get the median of these values\n",
    "        med_abs_deviation = np.median(diff)\n",
    "\n",
    "        # calcualte the next threshold with the median\n",
    "        # 1.486 used when assuming a normal distribution\n",
    "        th_1 = median + 3 * 1.486 * med_abs_deviation\n",
    "        # if the thresholds are too different, redo the while loop\n",
    "        if abs(th_0 - th_1) > 1:\n",
    "            th_0 = th_1\n",
    "        # else, set the final threshold to the current one, break the while loop and return values\n",
    "        else:\n",
    "            saccade_thresh = th_1\n",
    "            threshs.append(saccade_thresh)\n",
    "            break\n",
    "    return saccade_thresh, threshs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e0ead-c2fe-4a73-9f80-2e2f0e8c0824",
   "metadata": {},
   "source": [
    "# Starts Here\n",
    "Continuos colliders method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf604b8-e5bc-433b-be11-810494d17a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0479_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0479_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0479_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:439: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(dist[index.index(start_idx) :])\n",
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:439: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(dist[index.index(start_idx) :])\n",
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-24f5e3ccebba>:505: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-6-24f5e3ccebba>:510: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361_5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-24f5e3ccebba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;31m# go through the list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mcurr_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfor_eye\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mnext_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfor_eye\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             result = self._constructor_sliced(\n\u001b[0m\u001b[1;32m   3762\u001b[0m                 \u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfrom_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mConstructor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \"\"\"\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2740\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2742\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             raise ValueError(\n\u001b[1;32m    143\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = \"/Volumes/TwoTeras/0_Experiment_1/Eye_Tracking/Pre_processed/04_Interpolated\" \n",
    "\n",
    "# csv files in the path\n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "  \n",
    "# defining an empty list to store \n",
    "# content\n",
    "data_frame = pd.DataFrame()\n",
    "content = []\n",
    "  \n",
    "# checking all the csv files in the \n",
    "# specified path\n",
    "for filename in files:\n",
    "    One_participant = pd.read_csv(filename)\n",
    "    # Here we identify the shifts on collider name\n",
    "    One_participant['Collider_shift'] = One_participant['Interpolated_collider'].shift(1) != One_participant['Interpolated_collider']\n",
    "    # Create calculate a cumulative sum of the collider changes\n",
    "    One_participant['counter'] = (One_participant['Collider_shift'] == True).cumsum()\n",
    "    # Shift the counter column by one row to align it with the correct row\n",
    "    One_participant['counter'] = One_participant['counter'].shift(1).fillna(0)\n",
    "    One_participantC = One_participant.copy()\n",
    "    #Create subset that only has the rows with shifts in colliders \n",
    "    One_participant_true = One_participant[One_participant['Collider_shift'] == True].reset_index().copy()\n",
    "    # Since shift converts index into float we change it back into int so that it can be read as index\n",
    "    One_participant_true[\"index_shift\"] = One_participant_true[\"index\"].shift(-1).astype('Int64')\n",
    "    # Calculate the difference in time between each shift\n",
    "    One_participant_true[\"Time_diff\"] = One_participant_true.timeStampDataPointEnd.diff(1).shift(-1)\n",
    "    One_participant_true.dropna(inplace=True)\n",
    "    #### Create the gaze column \n",
    "    One_participant[\"Time_of_Gaze\"] = np.nan\n",
    "    low = One_participant_true[\"index\"].to_list()\n",
    "    up = One_participant_true[\"index_shift\"].to_list()\n",
    "    time =  One_participant_true[\"Time_diff\"].to_list()\n",
    "    ranges = list(zip(low, up))\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        One_participant.loc[lower:upper,\"Time_of_Gaze\"]  = time[i]\n",
    "    One_participant[\"Gaze\"] = np.where(One_participant[\"Time_of_Gaze\"] > .250, \"Gaze\", \"Movement\")\n",
    "    One_participant_true[\"Gaze\"] = np.where(One_participant_true[\"Time_diff\"] > .250, \"Gaze\", \"Movement\")\n",
    "    low = []\n",
    "    up = []\n",
    "    \n",
    "    ######## Debbies Algorithm ########\n",
    "    \n",
    "    for_eye = One_participant.copy()\n",
    "    time = for_eye[\"timeStampDataPointEnd\"].tolist()\n",
    "    \n",
    "    ## Calculate Angular velocities\n",
    "    # get individual coordinates\n",
    "    subj = list(zip( for_eye[\"eyePositionCombinedWorld.x\"],for_eye[\"eyePositionCombinedWorld.y\"],for_eye[\"eyePositionCombinedWorld.z\"]))\n",
    "    hpoo = list(zip(for_eye[\"hitPointOnObject_x\"], for_eye[\"hitPointOnObject_y\"],for_eye[\"hitPointOnObject_z\"]))\n",
    "    # v_gaze_vec: get difference in hpoo\n",
    "    v_gaze_vec = list(zip(for_eye[\"hitPointOnObject_x\"].diff(), for_eye[\"hitPointOnObject_y\"].diff(),for_eye[\"hitPointOnObject_z\"].diff()))\n",
    "    # get difference in time:\n",
    "    ts = for_eye[\"timeStampDataPointEnd\"].diff().tolist()\n",
    "    # gaze_vec(t) is a unit vector in the direction of the gaze (eye+head) in world coordinates\n",
    "    g_vec = list(np.subtract(hpoo, subj))\n",
    "    gaze_vec = [np.array(v) / np.linalg.norm(np.array(v)) for v in g_vec]\n",
    "    # v_gaze_inplane: is a scalar indicating the velocity in world coordinates at the location that is gazed at orthogonal to the gaze axis.\n",
    "    z1 = [np.dot(v_gaze_vec_i, gaze_vec_i) for v_gaze_vec_i, gaze_vec_i in zip(v_gaze_vec, gaze_vec)]\n",
    "    # z = (<v_gaze_vec(t), gaze_vec(t)> * gaze_vec(t))\n",
    "    z = [z1[element] * np.array(gaze_vec[element]) for element in range(len(z1))]\n",
    "    # ||v_gaze_vec(t) - z||\n",
    "    v_gaze_inplane = np.linalg.norm(np.array(v_gaze_vec) - z, axis=-1)\n",
    "    #Eucledian distance between eye coordinates and hit on object\n",
    "    sub_hpoo = np.linalg.norm(np.array(subj) - np.array(hpoo), axis=-1)\n",
    "    # arctan2(v_gaze_inplane, sub_hpoo)\n",
    "    w_gaze = np.arctan2(v_gaze_inplane, sub_hpoo).tolist()\n",
    "    # Turn angle of radians into degrees over seconds \n",
    "    w_gaze = [(w / ts[idx] * 180 / math.pi) for idx, w in enumerate(w_gaze)]\n",
    "    # save df\n",
    "    for_eye[\"combined_vel\"] = w_gaze\n",
    "   \n",
    "    ### 10 second for threshold calculation starts here\n",
    "    \n",
    "    int_len = 10  # number of seconds of the interval\n",
    "    time = for_eye[\"timeStampDataPointEnd\"].values\n",
    "    start = [time[0]]\n",
    "    end = []\n",
    "    start_idx = [0]\n",
    "    end_idx = []\n",
    "    for t, ti in enumerate(time[1:], start=1):\n",
    "        if ti - start[-1] > int_len:\n",
    "            end.append(time[t - 1])\n",
    "            end_idx.append(t - 1)\n",
    "            start.append(ti)\n",
    "            start_idx.append(t)\n",
    "    # add the last timepoint to end\n",
    "    end.append(time[-1])\n",
    "    end_idx.append(len(time))\n",
    "\n",
    "    # save it as new df\n",
    "    int_data = pd.DataFrame({\n",
    "        \"start\": start,\n",
    "        \"end\": end,\n",
    "        \"start_idx\": start_idx,\n",
    "        \"end_idx\": end_idx\n",
    "    })\n",
    "    \n",
    "    combined_vel = for_eye[\"combined_vel\"]\n",
    "\n",
    "    # to add the final thresholds to for each segement\n",
    "    scct = []\n",
    "    for s, srt in enumerate(int_data[\"start\"].values):\n",
    "        # get the slice of the combined velocity\n",
    "        angular_vel = combined_vel[start_idx[s] : end_idx[s]]\n",
    "        # use the at_mad function to caluclate the threshold\n",
    "        saccade_th, thres = at_mad(angular_vel)\n",
    "        if np.isnan(saccade_th):\n",
    "            scct.append(thres[0])\n",
    "        else:\n",
    "            # add it to scct\n",
    "            scct.append(saccade_th)\n",
    "\n",
    "    # add it to int_data and save\n",
    "    int_data[\"thresh\"] = scct\n",
    "    ranges = list(zip(int_data.start_idx, int_data.end_idx))    \n",
    "    \n",
    "    # go through all time intervals repeat the threshold as often as the time interval is long\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        for_eye.loc[lower:upper,\"thresh\"]  = int_data[\"thresh\"][i]\n",
    "    \n",
    "    # go through combined velocity and save all that are bigger than the threshold\n",
    "    # Everywhere  where there is Nans that is a saccade meaning this are the cells that are really fast OR ####### we had nan on the combined velocity #######\n",
    "    for_eye[\"isFix\"] = np.where(for_eye['combined_vel'] < for_eye[\"thresh\"], for_eye['combined_vel'], np.nan)\n",
    "    \n",
    "    ### reset the 10 second marks and the data set that contains them ###\n",
    "    # specify the variables you want to delete in a list\n",
    "    to_delete = [int_data, start, end, start_idx, end_idx]\n",
    "    # delete the variables using a loop\n",
    "    for Object in to_delete:\n",
    "        del Object\n",
    "\n",
    "    ####\n",
    "    for_eye.reset_index(inplace=True)\n",
    "    \n",
    "    min_sacc_dur = 0.02  # min sacc duration\n",
    "    min_gaze_dur = 0.04  # min gaze duration (Ashima uses 0.05)\n",
    "    time = for_eye.timeStampDataPointEnd.values\n",
    "    index = for_eye.index.tolist()  # index of df for easier use\n",
    "    start_time = time[0]  # update for each change\n",
    "    start_idx = index[0]  # will be updated each event and used to add to the lists\n",
    "\n",
    "    # to save:\n",
    "    isFix = []\n",
    "    combined_vel = []\n",
    "\n",
    "    # if the first sample does not have any data\n",
    "    if pd.isna(for_eye.loc[0, \"combined_vel\"]) and not pd.isna(for_eye.loc[1, \"combined_vel\"]):\n",
    "        start_time = time[1]   # update for each change\n",
    "        start_idx = index[1]  # will be updated each event and used to add to the lists\n",
    "        isFix = [np.nan]\n",
    "        combined_vel = [np.nan]\n",
    "\n",
    "    # starting with a sacc\n",
    "    if pd.isna(for_eye.loc[start_idx,\"isFix\"]):\n",
    "        event = 0  # == sacc\n",
    "    # starting with a gaze\n",
    "    else:\n",
    "        event = 1  # == gaze\n",
    "\n",
    "    # go through the list:\n",
    "    for idx in index[index.index(start_idx) : -1]:\n",
    "        curr_line = for_eye.loc[idx]\n",
    "        next_line = for_eye.loc[idx+1]\n",
    "\n",
    "        # gaze (--> sacc): now gaze, next one is sacc\n",
    "        if not pd.isna(curr_line.isFix) and pd.isna(next_line.isFix):\n",
    "            # if the event is too small but we are currently in a big gaze, keep isFix change combined_vel\n",
    "            if event == 1 and next_line.timeStampDataPointEnd - start_time < min_gaze_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event to small and we are in big saccade, change isFix, change combined_vel\n",
    "            elif event == 0 and next_line.timeStampDataPointEnd - start_time < min_gaze_dur:\n",
    "                isFix = isFix + [np.nan] * (idx + 1 - start_idx)\n",
    "                combined_vel = combined_vel + [np.nan] * (idx + 1 - start_idx)\n",
    "            # elif current event big enough, keep isFix and keep combined_vel and change event to 1,update length\n",
    "            elif next_line.timeStampDataPointEnd - start_time >= min_gaze_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = (\n",
    "                    combined_vel\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # keep combined_vel\n",
    "                event = 1  # change events\n",
    "            # update start_time and start_idx\n",
    "            start_idx = idx + 1\n",
    "            start_time = for_eye.loc[idx + 1][\"timeStampDataPointEnd\"]\n",
    "\n",
    "        # sacc (--> gaze): now sacc, next one is gaze\n",
    "        elif pd.isna(curr_line.isFix) and not pd.isna(next_line.isFix):\n",
    "            # if the event is too small and we are currently in a big sacc, keep isFix change combined_vel\n",
    "            if event == 0 and next_line.timeStampDataPointEnd - start_time < min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event to small but we are in big gaze, change isFix, change combined_vel\n",
    "            elif event == 1 and next_line.timeStampDataPointEnd - start_time < min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # change isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event big enough, keep isFix and keep combined_vel and change event to 0,update length\n",
    "            elif next_line.timeStampDataPointEnd - start_time >= min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = (\n",
    "                    combined_vel\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # keep combined_vel\n",
    "                event = 0  # change events\n",
    "            # update start_time and start_idx\n",
    "            start_idx = idx + 1\n",
    "            start_time = for_eye.loc[idx + 1][\"timeStampDataPointEnd\"]\n",
    "\n",
    "        # last index:\n",
    "        if idx + 1 == index[-1]:\n",
    "            # gaze:\n",
    "            if not pd.isna(next_line.isFix):\n",
    "                # if the event is too small but we are currently in a big gaze, keep isFix change combined_vel\n",
    "                if (\n",
    "                    event == 1\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_gaze_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event to small and we are in big saccade, change isFix, change combined_vel\n",
    "                elif (\n",
    "                    event == 0\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_gaze_dur\n",
    "                ):\n",
    "                    isFix = isFix + [np.nan] * (idx + 2 - start_idx)\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )\n",
    "                # elif current event big enough, keep isFix and keep combined_vel and change event to 1,update length\n",
    "                elif next_line.timeStampDataPointEnd + 0.011 - start_time >= min_gaze_dur:\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = (\n",
    "                        combined_vel\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # keep combined_vel\n",
    "            # sacc:\n",
    "            elif math.isnan(next_line.isFix):\n",
    "                # if the event is too small and we are currently in a big sacc, keep isFix change combined_vel\n",
    "                if (\n",
    "                    event == 0\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_sacc_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event to small but we are in big gaze, change isFix, change combined_vel\n",
    "                elif (\n",
    "                    event == 1\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_sacc_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # change isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event big enough, keep isFix and keep combined_vel and change event to 0,update length\n",
    "                elif next_line.timeStampDataPointEnd + 0.011 - start_time >= min_sacc_dur:\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = (\n",
    "                        combined_vel\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # keep combined_vel\n",
    "\n",
    "    # save everything:\n",
    "    for_eye[\"isFix\"] = isFix\n",
    "    for_eye[\"corrected_vel\"] = combined_vel\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    \n",
    "    time = for_eye.timeStampDataPointEnd.tolist()\n",
    "    \n",
    "    ########## EVENTS, LENGTH, AVG DISTANCE, NAME OF OBJECT ##########\n",
    "    index = for_eye.index.tolist()  # index of df for easier use\n",
    "\n",
    "    events = [np.nan] * len(\n",
    "        for_eye\n",
    "    )  # sacc begin == 1, sacc end == -1; gaze begin == 2, gaze end == -2\n",
    "\n",
    "    # if the first sample does not have any data\n",
    "    if math.isnan(for_eye.iloc[0][\"combined_vel\"]) and not math.isnan(\n",
    "        for_eye.iloc[1][\"combined_vel\"]\n",
    "    ):\n",
    "        start_idx = index[\n",
    "            1\n",
    "        ]  # will be updated each event and used to add to the lists\n",
    "        events[1] = 2\n",
    "        length = [np.nan]\n",
    "        dist = [\n",
    "            np.nan\n",
    "        ]  # to save the distance to the hitpoint at each timestamps\n",
    "        avg_dist = [\n",
    "            np.nan\n",
    "        ]  # to save the average distance of collider(s) during event\n",
    "        names = [np.nan]  # to save the name of the current gaze\n",
    "    else:\n",
    "        start_idx = index[\n",
    "            0\n",
    "        ]  # will be updated each event and used to add to the lists\n",
    "        length = []\n",
    "        dist = []  # to save the distance to the hitpoint at each timestamps\n",
    "        avg_dist = (\n",
    "            []\n",
    "        )  # to save the average distance of collider(s) during event\n",
    "        names = []  # to save the name of the current gaze\n",
    "        if math.isnan(for_eye.iloc[index[0]][\"combined_vel\"]):\n",
    "            events[0] = 1\n",
    "        else:\n",
    "            events[0] = 2\n",
    "\n",
    "    start_time = for_eye.loc[start_idx][\"timeStampDataPointEnd\"].tolist()\n",
    "    # go through the list:\n",
    "    for idx in index[index.index(start_idx) : -1]:\n",
    "        curr_line = for_eye.loc[idx]\n",
    "        next_line = for_eye.loc[idx + 1]\n",
    "\n",
    "        # distance:\n",
    "        hpoo = np.array(\n",
    "            [curr_line.hitPointOnObject_x, curr_line.hitPointOnObject_y, curr_line.hitPointOnObject_z]\n",
    "        )  # hitpoints on object\n",
    "        coord_orig = np.array(\n",
    "            [\n",
    "                curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.z\"],\n",
    "            ]\n",
    "        )  # position of eyes\n",
    "        dist = dist + [\n",
    "            np.linalg.norm(hpoo - coord_orig)\n",
    "        ]  # calculate to distance at this timpoint\n",
    "\n",
    "        # gaze --> sacc: now gaze, next one is sacc\n",
    "        if not math.isnan(curr_line.isFix) and math.isnan(next_line.isFix):\n",
    "            # get name:\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:idx, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 1 - start_idx)\n",
    "            # length, distance, events\n",
    "            length = length + [curr_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # length of event\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            events[index.index(idx)] = -2  # end of gaze\n",
    "            events[index.index(idx) + 1] = 1  # beginning of sacc\n",
    "            # new idx\n",
    "            start_time = curr_line.timeStampDataPointEnd\n",
    "            start_idx = idx + 1\n",
    "\n",
    "        # sacc --> gaze: now sacc, next one is gaze\n",
    "        elif math.isnan(curr_line.isFix) and not math.isnan(next_line.isFix):\n",
    "            # get name:\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:idx, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 1 - start_idx)\n",
    "            # length, distance, events\n",
    "            length = length + [curr_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # length of event\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            events[index.index(idx)] = -1  # end of sacc\n",
    "            events[index.index(idx) + 1] = 2  # beginning of gaze\n",
    "            # new idx\n",
    "            start_time = curr_line.timeStampDataPointEnd\n",
    "            start_idx = idx + 1\n",
    "\n",
    "        # last index:\n",
    "        if idx + 1 == index[-1]:\n",
    "            # gaze:\n",
    "            if not math.isnan(next_line.isFix):\n",
    "                events[-1] = -2  # end of gaze\n",
    "            # sacc:\n",
    "            elif math.isnan(next_line.isFix):\n",
    "                events[-1] = -1  # end of sacc\n",
    "            length = length + [next_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 2 - start_idx\n",
    "            )  # length of event\n",
    "            # distance\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 2 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            hpoo = np.array(\n",
    "                [curr_line.hitPointOnObject_x, curr_line.hitPointOnObject_y, curr_line.hitPointOnObject_z]\n",
    "            )  # hitpoints on object\n",
    "            coord_orig = np.array(\n",
    "                [\n",
    "                    curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                    curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                    curr_line[\"eyePositionCombinedWorld.z\"],\n",
    "                ]\n",
    "            )  # position of eyes\n",
    "            dist = dist + [\n",
    "                np.linalg.norm(hpoo - coord_orig)\n",
    "            ]  # calculate to distance at this timpoint\n",
    "            # names\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 2 - start_idx)\n",
    "    # save everything:\n",
    "    for_eye[\"events\"] = events\n",
    "    for_eye[\"length\"] = length\n",
    "    for_eye[\"distance\"] = dist\n",
    "    for_eye[\"avg_dist\"] = avg_dist\n",
    "    for_eye[\"names\"] = names\n",
    "    # display(for_eye[['time','isFix','events','hon_all','names']])\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    # Change average distance to correct for the potential of other events \n",
    "    # so distance and avg_dist\n",
    "\n",
    "    # total lists:\n",
    "    all_dist = []\n",
    "    avg_dist = []\n",
    "\n",
    "    # updated after each gaze\n",
    "    dist = []\n",
    "    hon_pos = []\n",
    "    dur_gaze = False\n",
    "\n",
    "    # during event:\n",
    "    # go through the list:      \n",
    "    for g,gz in enumerate(for_eye['events']):\n",
    "        curr_line = for_eye.loc[g]\n",
    "        if gz == 2.0 or gz == 1.0:\n",
    "            dur_gaze = True\n",
    "            # get the gazed at object\n",
    "            curr_gaze = curr_line.names\n",
    "        # if you are currently in a gaze:\n",
    "        if dur_gaze:\n",
    "            # if you are currently having the correct element, add the position\n",
    "            if curr_line.Interpolated_collider == curr_gaze:    \n",
    "                hon_pos = hon_pos + [[curr_line.hitPointOnObject_x,\n",
    "                    curr_line.hitPointOnObject_y,\n",
    "                    curr_line.hitPointOnObject_z,]]\n",
    "            dist = dist + [np.array([curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.z\"],])]\n",
    "\n",
    "        # once the gaze is over, take the avg_dist\n",
    "        if gz == -2.0 or gz == -1.0:\n",
    "            hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
    "            # calculate to distance at this timpoint\n",
    "            dist = [np.linalg.norm(hon_pos[c] - dist[c]) for c in range(len(dist))]\n",
    "            all_dist = all_dist + dist\n",
    "            # average distance during the gaze event\n",
    "            avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n",
    "\n",
    "            # reset everything:\n",
    "            dist = []\n",
    "            hon_pos = []\n",
    "            dur_gaze = False\n",
    "\n",
    "        # if there are parts that are neither gaze nor saccade:\n",
    "        if (not dur_gaze) and (gz not in [2.0,1.0]) and (len(all_dist) + len(dist) != g + 1):\n",
    "            all_dist = all_dist + [np.nan]\n",
    "            avg_dist = avg_dist + [np.nan]\n",
    "\n",
    "        if len(all_dist) + len(dist) != g + 1:\n",
    "            display(g)\n",
    "\n",
    "    if dur_gaze:\n",
    "        hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
    "        # calculate to distance at this timpoint\n",
    "        dist = [np.linalg.norm(hon_pos[c] - dist[c]) for c in range(len(dist))]\n",
    "        all_dist = all_dist + dist\n",
    "        # average distance during the gaze event\n",
    "        avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n",
    "\n",
    "    # add them to for_eye\n",
    "    for_eye['distance'] = all_dist\n",
    "    for_eye['avg_dist'] = avg_dist\n",
    "    \n",
    "    for_eye[\"names\"] =  for_eye.names.fillna(method='ffill').fillna(method='bfill')\n",
    "    for_eye['Collider_CategoricalN'] = for_eye['names'].apply(lambda x: next((val for key, val in patterns.items() if re.match(key, x)), default_val))\n",
    "    \n",
    "\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    \n",
    "    # Define the condition and the string to add\n",
    "    Mask_1f = ((for_eye['Collider_CategoricalN'] == \"Active_Agent\") & (for_eye['Face_Hits'] == \"Face\")) | ((for_eye['Collider_CategoricalN'] == \"Passive_Agent\") & (for_eye['Face_Hits'] == \"Face\"))\n",
    "    Mask_2f  = ((for_eye['Collider_Categorical'] == \"Active_Agent\") | (for_eye['Collider_Categorical'] == \"Passive_Agent\")) & (for_eye['Face_Hits'] == \"Face\")    \n",
    "    string_to_add = \"_Face\"\n",
    "    # Use the loc method to index the rows where the condition is met\n",
    "    for_eye.loc[Mask_1f, 'Collider_CategoricalN'] = for_eye.loc[Mask_1f, 'Collider_CategoricalN'] + string_to_add\n",
    "    for_eye.loc[Mask_2f, 'Collider_Categorical'] = for_eye.loc[Mask_2f, 'Collider_Categorical'] + string_to_add\n",
    "    for_eye.to_csv(f\"/Volumes/TwoTeras/0_Experiment_1/Eye_Tracking/Pre_processed/05_Debbies_gaze/{filename[-10:-4]}.csv\", index=True)\n",
    "    print(filename[-10:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9b047-5700-4f75-b0e2-29e9fb869910",
   "metadata": {},
   "source": [
    "# Debbies plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e93b3-918b-412a-94f9-40440dc22dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye = pd.read_csv(\"/Volumes/TwoTeras/0_Experiment_1/Eye_Tracking/Pre_processed/03_Debbies_gaze/One_participant_WDC.csv\", index_col=\"timeStampDataPointEnd\")\n",
    "\n",
    "window_lower = for_eye.index.tolist()[2070]\n",
    "window_upper = for_eye.index.tolist()[2270]\n",
    "\n",
    "titel = \"Hit Points of Gazes\"\n",
    "            \n",
    "\n",
    "# get time:\n",
    "ts = for_eye.index.tolist()  # to make it easier\n",
    "time = ts[\n",
    "    ts.index(\n",
    "        list(filter(lambda i: i > window_lower, ts))[0]\n",
    "    ) : ts.index(list(filter(lambda i: i < window_upper, ts))[-1])\n",
    "    + 1\n",
    "]  # get all timestamps in the important time window\n",
    "\n",
    "# get shorter df:\n",
    "for_eye = for_eye.iloc[ts.index(time[0]) : (ts.index(time[-1]) + 1)]\n",
    "\n",
    "\n",
    "# hon: for showing lines in plot\n",
    "hon = for_eye[\"Interpolated_collider\"].tolist()\n",
    "new_col = [\n",
    "    hon[n] if hon[n] != hon[n - 1] and not pd.isnull(hon[n]) else np.nan\n",
    "    for n in range(len(hon))\n",
    "]\n",
    "\n",
    "hon_ts = [\n",
    "    ti for cnt, ti in enumerate(time) if isinstance(new_col[cnt], str)\n",
    "]  # timestamps\n",
    "\n",
    "# get gazes:\n",
    "gaze = for_eye[~for_eye[\"isFix\"].isnull()]\n",
    "gaze = gaze.rename({'hitPointOnObject_x': 'xgaze', 'hitPointOnObject_y': 'ygaze', 'hitPointOnObject_z': 'zgaze'}, axis=1)\n",
    "\n",
    "sacc = for_eye[~for_eye.index.isin(gaze.index)]\n",
    "sacc = sacc.rename({'hitPointOnObject_x': 'xsacc', 'hitPointOnObject_y': 'ysacc', 'hitPointOnObject_z': 'zsacc'}, axis=1)\n",
    "\n",
    "\n",
    "# plot it:\n",
    "sns.set(rc={\"figure.figsize\": (17, 9)})\n",
    "sns.set_style(\n",
    "    \"white\"\n",
    ")  # styledict, or one of {darkgrid, whitegrid, dark, white, ticks}\n",
    "\n",
    "f, (axis) = plt.subplots(2, 1)\n",
    "\n",
    "\n",
    "for x, xc in enumerate(hon_ts):\n",
    "    if not np.isnan(xc):\n",
    "        axis[0].axvline(\n",
    "            x=xc, color=\"#987284\", alpha=0.2, label=\"_Hidden label\"\n",
    "        )\n",
    "\n",
    "color_gaze = {\n",
    "    \"xgaze\": \"#5FAD56\",\n",
    "    \"ygaze\": \"#27408B\",\n",
    "    \"zgaze\": \"#4C86A8\",\n",
    "}\n",
    "color_sacc = {\n",
    "    \"xsacc\": \"#BA1200\",\n",
    "    \"ysacc\": \"#CD96CD\",\n",
    "    \"zsacc\": \"#F0A202\",\n",
    "}\n",
    "\n",
    "gaze[[\"xgaze\", \"ygaze\", \"zgaze\"]].plot(\n",
    "    color=[\n",
    "        color_gaze.get(x, \"#333333\")\n",
    "        for x in gaze[[\"xgaze\", \"ygaze\", \"zgaze\"]]\n",
    "    ],\n",
    "    ax=axis[0],\n",
    "    marker=\"o\",\n",
    "    ls=\"\",\n",
    ")\n",
    "\n",
    "sacc[[\"xsacc\", \"ysacc\", \"zsacc\"]].plot(\n",
    "    color=[\n",
    "        color_sacc.get(x, \"#333333\")\n",
    "        for x in sacc[[\"xsacc\", \"ysacc\", \"zsacc\"]]\n",
    "    ],\n",
    "    ax=axis[0],\n",
    "    marker=\"o\",\n",
    "    ls=\"\",\n",
    ")\n",
    "\n",
    "axis[0].set_title(\n",
    "    titel,\n",
    "    fontsize=22,\n",
    "    fontweight='bold',\n",
    ")\n",
    "axis[0].legend(loc=\"upper right\", fontsize=18)\n",
    "axis[0].xaxis.label.set_visible(False)\n",
    "axis[0].set_ylabel(\"coordinates\", fontsize=20)\n",
    "axis[0].yaxis.set_tick_params(labelsize = 14) # change tick size\n",
    "axis[0].xaxis.set_tick_params(labelsize = 14) \n",
    "\n",
    "\n",
    "\n",
    "axis[1].plot(time, for_eye[\"combined_vel\"].tolist(), \"g\", label = \"combined_vel\")\n",
    "axis[1].plot(time, for_eye[\"thresh\"].tolist(), \"r\", label = \"threshold\")\n",
    "\n",
    "#axis[3].plot(time, long_events_mad, \"k\")\n",
    "## axis[2].plot(time, blinks, \"b\")  # blinks\n",
    "axis[1].set_ylim(0, 600)\n",
    "axis[1].set_title(\n",
    "        \"Velocities\",\n",
    "        fontsize=22,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "axis[1].legend(loc=\"upper right\", fontsize=18)\n",
    "#plt.xticks(fontsize=14)\n",
    "#ax.set_xticklabels(time,fontsize=20)\n",
    "#plt.suptitle(uid, fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "axis[1].set_xlabel(\"time (sec)\", fontsize=20)\n",
    "axis[1].set_ylabel(\"veloctiy\", fontsize=20)\n",
    "axis[1].yaxis.set_tick_params(labelsize = 14) # change tick size\n",
    "axis[1].xaxis.set_tick_params(labelsize = 14) \n",
    "\n",
    "plt.suptitle(titel, fontsize=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378392c-2700-4f37-b716-a04d6c39e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

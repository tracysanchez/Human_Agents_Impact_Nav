{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0f35eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Added cell to set Working Directory to your location\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c4e6732",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/SSD/00_Data_Processing/Exploration_short'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Volumes/SSD/00_Data_Processing/Exploration_short\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b0a50b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Columns to keep from the raw data.\n",
    "cols_to_keep = ['timeStampDataPointStart', 'timeStampDataPointEnd', 'combinedGazeValidityBitmask', 'rayCastHitsCombinedEyes', 'hmdPosition.x', 'hmdPosition.y',\n",
    "                'hmdPosition.z', 'hmdDirectionForward.x', 'hmdDirectionForward.y', 'hmdDirectionForward.z', 'hmdDirectionRight.x', 'hmdDirectionRight.y',\n",
    "                'bodyTrackerRotation.x', 'bodyTrackerRotation.y','bodyTrackerRotation.z','playerBodyPosition.x', 'playerBodyPosition.y', 'playerBodyPosition.z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e6d49b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8673', '8695', '9472']\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Volumes/SSD/00_Data_Processing/Exploration_short'\n",
    "processed_data = '/Volumes/SSD/00_Data_Processing/Pre_processed'\n",
    "\n",
    "# Getting the Folder without hidden files in ascending order\n",
    "DATA_FOLDER = sorted([f for f in os.listdir(data_path) if not f.startswith('.')], key=str.lower)\n",
    "PROCESSED_DATA_FOLDER = sorted([f for f in os.listdir(processed_data) if not f.startswith('.')], key=str.lower)\n",
    "subIDs = []\n",
    "for sub in DATA_FOLDER:\n",
    "    if sub[0:4].isdigit():\n",
    "        subIDs.append(int(sub[0:4]))\n",
    "    else:\n",
    "        pass\n",
    "subIDs = np.unique(subIDs)\n",
    "#Sincesome participant IDs start with 0, we format them to show it in the string type\n",
    "IDstrings = ['{:04d}'.format(id) for id in subIDs]\n",
    "print(IDstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2015955e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8673/*.json', '8695/*.json', '9472/*.json']\n"
     ]
    }
   ],
   "source": [
    "#Create a generalized path for all json files per participant\n",
    "paths = [ID +  \"/*.json\" for ID in IDstrings]\n",
    "print(paths)\n",
    "#Create a sorted list of the paths to open de jsons\n",
    "Sorted_individual_jsons = sorted([filename for path in paths for filename in glob.glob(path)], key=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f647a905",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 8673 Session 05 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:12:48 2022\n",
      "Appended\n",
      "Subject 8673 Session 01 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:13:31 2022\n",
      "Appended\n",
      "Subject 8673 Session 01 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:14:19 2022\n",
      "Appended\n",
      "Subject 8673 Session 01 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:15:03 2022\n",
      "Appended\n",
      "Subject 8673 Session 02 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:15:49 2022\n",
      "Appended\n",
      "Subject 8673 Session 02 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:16:37 2022\n",
      "Appended\n",
      "Subject 8673 Session 02 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:17:25 2022\n",
      "Appended\n",
      "Subject 8673 Session 03 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:18:12 2022\n",
      "Appended\n",
      "Subject 8673 Session 03 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:19:04 2022\n",
      "Appended\n",
      "Subject 8673 Session 03 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:19:57 2022\n",
      "Appended\n",
      "Subject 8673 Session 04 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:20:45 2022\n",
      "Appended\n",
      "Subject 8673 Session 04 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:21:38 2022\n",
      "Appended\n",
      "Subject 8673 Session 04 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:22:30 2022\n",
      "Appended\n",
      "Subject 8673 Session 05 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:23:26 2022\n",
      "Appended\n",
      "Subject 8673 Session 05 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:24:28 2022\n",
      "Appended\n",
      "Saved\n",
      "Subject 8695 Session 05 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:26:38 2022\n",
      "Appended\n",
      "Subject 8695 Session 05 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:27:24 2022\n",
      "Appended\n",
      "Subject 8695 Session 02 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:28:11 2022\n",
      "Appended\n",
      "Subject 8695 Session 05 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:28:59 2022\n",
      "Appended\n",
      "Subject 8695 Session 02 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:29:50 2022\n",
      "Appended\n",
      "Subject 8695 Session 02 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:30:37 2022\n",
      "Appended\n",
      "Subject 8695 Session 03 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:31:25 2022\n",
      "Appended\n",
      "Subject 8695 Session 03 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:32:16 2022\n",
      "Appended\n",
      "Subject 8695 Session 03 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:33:03 2022\n",
      "Appended\n",
      "Subject 8695 Session 04 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:33:53 2022\n",
      "Appended\n",
      "Subject 8695 Session 04 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:34:46 2022\n",
      "Appended\n",
      "Subject 8695 Session 04 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:35:40 2022\n",
      "Appended\n",
      "Saved\n",
      "Subject 9472 Session 05 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:37:36 2022\n",
      "Appended\n",
      "Subject 9472 Session 01 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:38:22 2022\n",
      "Appended\n",
      "Subject 9472 Session 01 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:39:09 2022\n",
      "Appended\n",
      "Subject 9472 Session 01 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:39:55 2022\n",
      "Appended\n",
      "Subject 9472 Session 02 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:40:43 2022\n",
      "Appended\n",
      "Subject 9472 Session 02 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:41:30 2022\n",
      "Appended\n",
      "Subject 9472 Session 02 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:42:18 2022\n",
      "Appended\n",
      "Subject 9472 Session 03 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:43:19 2022\n",
      "Appended\n",
      "Subject 9472 Session 03 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:44:09 2022\n",
      "Appended\n",
      "Subject 9472 Session 03 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:45:00 2022\n",
      "Appended\n",
      "Subject 9472 Session 04 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:46:00 2022\n",
      "Appended\n",
      "Subject 9472 Session 04 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:46:57 2022\n",
      "Appended\n",
      "Subject 9472 Session 04 Section 3 has been normalized\n",
      "time is:  Wed Nov 30 13:47:54 2022\n",
      "Appended\n",
      "Subject 9472 Session 05 Section 1 has been normalized\n",
      "time is:  Wed Nov 30 13:48:50 2022\n",
      "Appended\n",
      "Subject 9472 Session 05 Section 2 has been normalized\n",
      "time is:  Wed Nov 30 13:49:50 2022\n",
      "Appended\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "data_raw = pd.DataFrame()\n",
    "\n",
    "# read every file name in folder\n",
    "for path in paths:\n",
    "    for filename in glob.glob(path):\n",
    "        with open(filename, 'r') as file:\n",
    "            try:\n",
    "                # make json files parsable\n",
    "                data = \"[\" + file.read()\n",
    "                data = data[:len(data)] + \"]\"\n",
    "                raw = json.loads(data)\n",
    "            except:\n",
    "                print(\"reading did not work\")\n",
    "                \n",
    "\n",
    "            # Uneast the higher level of each file\n",
    "            currentDF_raw = pd.json_normalize(raw[0]['trials'][0]['dataPoints'])\n",
    "            print( \"Subject \" + str(filename[5:9]) + \" Session \" + str(filename[17:19]) +\" Section \" + str(filename[23:24]) + \" has been normalized\")\n",
    "            #Reduce columns to just necessary information\n",
    "            reduced_data = currentDF_raw.loc[:, cols_to_keep]\n",
    "            print('time is: ', time.ctime())\n",
    "\n",
    "            # insert participant id and session information from the file name\n",
    "            reduced_data.insert(0, \"SubjectID\", [int(filename[5:9])] * reduced_data.shape[0], True)\n",
    "            reduced_data.insert(1, \"Session\", [int(filename[17:19])] * reduced_data.shape[0], True)\n",
    "            reduced_data.insert(2, \"SessionSubsection\", [int(filename[23:24])] * reduced_data.shape[0], True)\n",
    "        data_raw = data_raw.append(reduced_data, ignore_index=True)\n",
    "        print('Appended')\n",
    "    data_raw.to_csv('/Volumes/SSD/00_Data_Processing/Pre_processed/00_Individuals_Flat/' + str(filename[5:9]) + \".csv\")\n",
    "    print('Saved')\n",
    "    data_raw = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c11fdf6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exploded = reduced_data['rayCastHitsCombinedEyes'].explode().apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88691c41-87c8-4620-b6d9-76703e3660ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"/Volumes/SSD/00_Data_Processing/Pre_processed/00_Individuals_Flat/*.csv\")                    \n",
    "combined_csv = pd.concat( [ pd.read_csv(f) for f in filenames ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcbd70-7eca-4971-989d-473cae765fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cabde071-e543-4639-8015-371ec2b19d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.to_csv(\"/Volumes/SSD/00_Data_Processing/Pre_processed/combined_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e68665-1e24-46bf-9dcd-80504f528721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Session</th>\n",
       "      <th>SessionSubsection</th>\n",
       "      <th>timeStampDataPointStart</th>\n",
       "      <th>timeStampDataPointEnd</th>\n",
       "      <th>combinedGazeValidityBitmask</th>\n",
       "      <th>rayCastHitsCombinedEyes</th>\n",
       "      <th>hmdPosition.x</th>\n",
       "      <th>hmdPosition.y</th>\n",
       "      <th>...</th>\n",
       "      <th>hmdDirectionForward.y</th>\n",
       "      <th>hmdDirectionForward.z</th>\n",
       "      <th>hmdDirectionRight.x</th>\n",
       "      <th>hmdDirectionRight.y</th>\n",
       "      <th>bodyTrackerRotation.x</th>\n",
       "      <th>bodyTrackerRotation.y</th>\n",
       "      <th>bodyTrackerRotation.z</th>\n",
       "      <th>playerBodyPosition.x</th>\n",
       "      <th>playerBodyPosition.y</th>\n",
       "      <th>playerBodyPosition.z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>479</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'hitPointOnObject': {'x': -73.16242218017578...</td>\n",
       "      <td>-94.648758</td>\n",
       "      <td>-0.409340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027602</td>\n",
       "      <td>0.958554</td>\n",
       "      <td>0.958661</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-94.788467</td>\n",
       "      <td>-1.957432</td>\n",
       "      <td>-138.283386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>479</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'hitPointOnObject': {'x': -73.16242218017578...</td>\n",
       "      <td>-94.648758</td>\n",
       "      <td>-0.409340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027602</td>\n",
       "      <td>0.958554</td>\n",
       "      <td>0.958661</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-94.788467</td>\n",
       "      <td>-1.957432</td>\n",
       "      <td>-138.283386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>479</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'hitPointOnObject': {'x': -72.61051940917969...</td>\n",
       "      <td>-94.648758</td>\n",
       "      <td>-0.409452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026794</td>\n",
       "      <td>0.958753</td>\n",
       "      <td>0.958849</td>\n",
       "      <td>0.016187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-94.788467</td>\n",
       "      <td>-1.957432</td>\n",
       "      <td>-138.283386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>479</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'hitPointOnObject': {'x': -72.61051940917969...</td>\n",
       "      <td>-94.648758</td>\n",
       "      <td>-0.409452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026794</td>\n",
       "      <td>0.958753</td>\n",
       "      <td>0.958849</td>\n",
       "      <td>0.016187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-94.788467</td>\n",
       "      <td>-1.957432</td>\n",
       "      <td>-138.283386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>479</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>1.653464e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'hitPointOnObject': {'x': -72.95903778076172...</td>\n",
       "      <td>-94.648819</td>\n",
       "      <td>-0.409578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.959344</td>\n",
       "      <td>0.959410</td>\n",
       "      <td>0.015804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-94.788467</td>\n",
       "      <td>-1.957432</td>\n",
       "      <td>-138.283386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SubjectID  Session  SessionSubsection  timeStampDataPointStart  \\\n",
       "0           0        479        5                  3             1.653464e+09   \n",
       "1           1        479        5                  3             1.653464e+09   \n",
       "2           2        479        5                  3             1.653464e+09   \n",
       "3           3        479        5                  3             1.653464e+09   \n",
       "4           4        479        5                  3             1.653464e+09   \n",
       "\n",
       "   timeStampDataPointEnd  combinedGazeValidityBitmask  \\\n",
       "0           1.653464e+09                            3   \n",
       "1           1.653464e+09                            3   \n",
       "2           1.653464e+09                            3   \n",
       "3           1.653464e+09                            3   \n",
       "4           1.653464e+09                            3   \n",
       "\n",
       "                             rayCastHitsCombinedEyes  hmdPosition.x  \\\n",
       "0  [{'hitPointOnObject': {'x': -73.16242218017578...     -94.648758   \n",
       "1  [{'hitPointOnObject': {'x': -73.16242218017578...     -94.648758   \n",
       "2  [{'hitPointOnObject': {'x': -72.61051940917969...     -94.648758   \n",
       "3  [{'hitPointOnObject': {'x': -72.61051940917969...     -94.648758   \n",
       "4  [{'hitPointOnObject': {'x': -72.95903778076172...     -94.648819   \n",
       "\n",
       "   hmdPosition.y  ...  hmdDirectionForward.y  hmdDirectionForward.z  \\\n",
       "0      -0.409340  ...               0.027602               0.958554   \n",
       "1      -0.409340  ...               0.027602               0.958554   \n",
       "2      -0.409452  ...               0.026794               0.958753   \n",
       "3      -0.409452  ...               0.026794               0.958753   \n",
       "4      -0.409578  ...               0.024862               0.959344   \n",
       "\n",
       "   hmdDirectionRight.x  hmdDirectionRight.y  bodyTrackerRotation.x  \\\n",
       "0             0.958661             0.016425                    0.0   \n",
       "1             0.958661             0.016425                    0.0   \n",
       "2             0.958849             0.016187                    0.0   \n",
       "3             0.958849             0.016187                    0.0   \n",
       "4             0.959410             0.015804                    0.0   \n",
       "\n",
       "   bodyTrackerRotation.y  bodyTrackerRotation.z  playerBodyPosition.x  \\\n",
       "0                    0.0                    0.0            -94.788467   \n",
       "1                    0.0                    0.0            -94.788467   \n",
       "2                    0.0                    0.0            -94.788467   \n",
       "3                    0.0                    0.0            -94.788467   \n",
       "4                    0.0                    0.0            -94.788467   \n",
       "\n",
       "   playerBodyPosition.y  playerBodyPosition.z  \n",
       "0             -1.957432           -138.283386  \n",
       "1             -1.957432           -138.283386  \n",
       "2             -1.957432           -138.283386  \n",
       "3             -1.957432           -138.283386  \n",
       "4             -1.957432           -138.283386  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9eca48b-f336-4772-981b-17258dbf6bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26914800, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c2de9b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5adcbb6c6141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memptyDF1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcolumns1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0memptyDF2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcolumns2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'columns1' is not defined"
     ]
    }
   ],
   "source": [
    "emptyDF1 = pd.DataFrame(np.nan,index=[0], columns= columns1)\n",
    "emptyDF2 = pd.DataFrame(np.nan,index=[0], columns= columns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c4590",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data loop through all subjects and sessions\n",
    "subcount = 0\n",
    "for subject in subIDs:\n",
    "    subcount +=1\n",
    "    print('Subject '\n",
    "          + str(subject)\n",
    "          + ' started - '\n",
    "          + str(subcount)\n",
    "          + '/'\n",
    "          + str(len(subIDs))\n",
    "          + ' subjects')\n",
    "    #     # Create empty dataframe for later concatenation\n",
    "    # complete_exploration_df = pd.DataFrame(columns = col_names)\n",
    "    #     complete_exploration_df.head()\n",
    "\n",
    "\n",
    "    # change dir into the subject folder\n",
    "    CURRENT_SUBJECT_FOLDER = sorted([f for f in os.listdir(DATA_PATH+str(subject))], key=str.lower)\n",
    "    # get the data files according to the subject, ignoring OnQuit files\n",
    "    subject_files = sorted([f for f in CURRENT_SUBJECT_FOLDER\n",
    "                            if f.startswith(str(subject)+'_Expl_S_') and f.endswith(\"OnQuit.json\") == False],\n",
    "                           key=str.lower)\n",
    "\n",
    "    # the following works as long as the data name format is as follows:\n",
    "    # 'subjectID'_Expl_S_'SessionNumber'_ET_'EyeTrackingSessionNumber'_'UnixTimestamp'.json\n",
    "    folder_files = list()\n",
    "\n",
    "    # loop through the subject folder and save all numbers\n",
    "    for file in subject_files:\n",
    "        folder_files.append(re.findall(r'\\d+', file))\n",
    "\n",
    "    # Extract all SubIDs (only one), SessionNumbers, ET_SessionNumbers (and Timestamps)\n",
    "    try:\n",
    "        SubID, SessionNumbers, ET_SessionNumbers, UnixTimestamp1, UnixTimeStamp2 = map(list, zip(*folder_files))\n",
    "    except:\n",
    "        print('\\tSubject '\n",
    "              + str(subject)\n",
    "              + ' Filename is not valid!')\n",
    "\n",
    "    #     print(SubID)\n",
    "    #     print(SessionNumbers)\n",
    "    #     print(ET_SessionNumbers)\n",
    "    #     print(UnixTimestamp1)\n",
    "    #     print(UnixTimeStamp2)\n",
    "\n",
    "    session_number = int(max(SessionNumbers)) # the maximum session number of the particular subject\n",
    "    ET_session_number = int(max(ET_SessionNumbers)) # the maximum ET session number of the particular subject\n",
    "\n",
    "\n",
    "    # print info of how many files were found\n",
    "\n",
    "    print(len(SubID), ' files were found for participant ', SubID[0])\n",
    "    print('A maximum of ', session_number, 'sessions were found and will be processed')\n",
    "\n",
    "    # --------- second layer - exploration session loop ---------\n",
    "\n",
    "    # loop over exploration sessions\n",
    "    for EXP_session in range(session_number):\n",
    "        # to avoid start at 0\n",
    "        EXP_session +=1\n",
    "\n",
    "        # extract the exploration data files for each session - but exclude OnQuit files\n",
    "        subject_data = sorted([f for f in CURRENT_SUBJECT_FOLDER if f.startswith(str(subject) + '_Expl_S_')\n",
    "                               and f.endswith(\"OnQuit.json\") == False], key=str.lower)\n",
    "\n",
    "\n",
    "        print(\"\\tTotal Sessionfiles: \"\n",
    "              + str(len(subject_data))\n",
    "              + \" - Exploration Session \"\n",
    "              + str(EXP_session))\n",
    "\n",
    "        ET_session_count = 0 # session count\n",
    "        # --------- third layer - eye tracking session loop ---------\n",
    "\n",
    "        # loop over separate eye tracking sessions\n",
    "        for fileName in subject_data:\n",
    "            ET_session_count+=1\n",
    "\n",
    "            print('load data of file ', fileName)\n",
    "\n",
    "            print('Path: ', DATA_PATH + str(subject) + '/' + fileName)\n",
    "            # open the JSON file as dictionary\n",
    "            with open(DATA_PATH + str(subject) + '/' + fileName) as datafile:\n",
    "                try:\n",
    "                    print(\"read file\")\n",
    "                    dataR = '['+ datafile.read()\n",
    "                    dataR = dataR[:len(dataR)] + \"]\"\n",
    "                except:\n",
    "                    print(\"reading did not work\")\n",
    "\n",
    "                subject_session = json.loads(dataR)\n",
    "                print(\"data loaded\")\n",
    "                print('time is: ', time.ctime())\n",
    "\n",
    "\n",
    "\n",
    "            ##################################################################################################################\n",
    "\n",
    "            # Data flattening part:\n",
    "            # first save the overall trial information\n",
    "\n",
    "\n",
    "            infoDF = pd.json_normalize(subject_session[0]['trials'][0])\n",
    "            infoDF = infoDF.drop(columns=['dataPoints'])\n",
    "            infoDF.insert(0,'FileInfo',fileName[0:18])\n",
    "            infoDF.to_csv(PROCESSED_DATA_PATH + fileName[0:18] + '_infoSummary.csv', index = False)\n",
    "            print('trial info saved')\n",
    "\n",
    "\n",
    "            # flatten the majority of the variables into currentDF data frame\n",
    "            currentDF_raw = pd.json_normalize(subject_session[0]['trials'][0]['dataPoints'])\n",
    "\n",
    "            # remove the 'rayCastHitsCombinedEyes' column as it still contains a nested data structure\n",
    "            dataDF = currentDF_raw.drop(columns=['rayCastHitsCombinedEyes'])\n",
    "\n",
    "            # create an empty data frame of the required size\n",
    "            rayCastData_df = pd.DataFrame(np.nan,index=range(len(subject_session[0]['trials'][0]['dataPoints'])), columns= columnsRCall)\n",
    "\n",
    "            # now loop through the individual trials and flatten the data\n",
    "            for index in range(len(subject_session[0]['trials'][0]['dataPoints'])):\n",
    "                # depending on the size of the ray cast data - flatten data and appand it to currentDF data frame\n",
    "                # the variables are renamed to make the differentiation of first and second order collider hits more intuitive\n",
    "                #lengthRCData = len(subject_session[0]['trials'][0]['dataPoints'][index]['rayCastHitsCombinedEyes'][0])\n",
    "                lengthRCData = len(currentDF_raw.at[index,'rayCastHitsCombinedEyes'])\n",
    "\n",
    "\n",
    "                if lengthRCData ==0: #case: no ray cast data is available = no collider was hit\n",
    "\n",
    "                    combineDF = pd.concat([emptyDF1, emptyDF2], axis=1)\n",
    "                    combineDF.insert(len(combineDF.columns), 'DataRow',index)\n",
    "\n",
    "\n",
    "                elif lengthRCData == 1: # case: only one collider was hit, there is no secondary hit\n",
    "\n",
    "                    pdRC1= pd.json_normalize(currentDF_raw.at[index,'rayCastHitsCombinedEyes'][0]).rename(\n",
    "                        columns = {'hitObjectColliderName':'hitObjectColliderName_1',\n",
    "                                   'hitColliderType':'hitColliderType_1',\n",
    "                                   'ordinalOfHit':'ordinalOfHit_1',\n",
    "                                   'hitPointOnObject.x':'hitPointOnObject.x_1',\n",
    "                                   'hitPointOnObject.y':'hitPointOnObject.y_1',\n",
    "                                   'hitPointOnObject.z':'hitPointOnObject.z_1',\n",
    "                                   'hitObjectColliderBoundsCenter.x':'hitObjectColliderBoundsCenter.x_1',\n",
    "                                   'hitObjectColliderBoundsCenter.y':'hitObjectColliderBoundsCenter.y_1',\n",
    "                                   'hitObjectColliderBoundsCenter.z':'hitObjectColliderBoundsCenter.z_1'})\n",
    "                    combineDF = pd.concat([pdRC1, emptyDF2], axis=1)\n",
    "                    combineDF.insert(len(combineDF.columns), 'DataRow',index)\n",
    "\n",
    "                elif lengthRCData == 2: # case: two collider were hit\n",
    "\n",
    "                    pdRC1= pd.json_normalize(currentDF_raw.at[index,'rayCastHitsCombinedEyes'][0]).rename(\n",
    "                        columns = {'hitObjectColliderName':'hitObjectColliderName_1',\n",
    "                                   'hitColliderType':'hitColliderType_1',\n",
    "                                   'ordinalOfHit':'ordinalOfHit_1',\n",
    "                                   'hitPointOnObject.x':'hitPointOnObject.x_1',\n",
    "                                   'hitPointOnObject.y':'hitPointOnObject.y_1',\n",
    "                                   'hitPointOnObject.z':'hitPointOnObject.z_1',\n",
    "                                   'hitObjectColliderBoundsCenter.x':'hitObjectColliderBoundsCenter.x_1',\n",
    "                                   'hitObjectColliderBoundsCenter.y':'hitObjectColliderBoundsCenter.y_1',\n",
    "                                   'hitObjectColliderBoundsCenter.z':'hitObjectColliderBoundsCenter.z_1'})\n",
    "                    pdRC2 = pd.json_normalize(currentDF_raw.at[index,'rayCastHitsCombinedEyes'][1]).rename(\n",
    "                        columns = {'hitObjectColliderName':'hitObjectColliderName_2',\n",
    "                                   'hitColliderType':'hitColliderType_2',\n",
    "                                   'ordinalOfHit':'ordinalOfHit_2',\n",
    "                                   'hitPointOnObject.x':'hitPointOnObject.x_2',\n",
    "                                   'hitPointOnObject.y':'hitPointOnObject.y_2',\n",
    "                                   'hitPointOnObject.z':'hitPointOnObject.z_2',\n",
    "                                   'hitObjectColliderBoundsCenter.x':'hitObjectColliderBoundsCenter.x_2',\n",
    "                                   'hitObjectColliderBoundsCenter.y':'hitObjectColliderBoundsCenter.y_2',\n",
    "                                   'hitObjectColliderBoundsCenter.z':'hitObjectColliderBoundsCenter.z_2'})\n",
    "                    combineDF = pd.concat([pdRC1, pdRC2], axis=1)\n",
    "                    combineDF.insert(len(combineDF.columns), 'DataRow',index)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    print('!!!an exception occured in the ray cast data flattening in trial ', index)\n",
    "\n",
    "                # now add the new data row to the data overview\n",
    "                # rayCastData_df = [rayCastData_df]\n",
    "\n",
    "\n",
    "                rayCastData_df.loc[index] = combineDF.loc[0]\n",
    "\n",
    "            flatData_df = pd.concat([dataDF,rayCastData_df],axis=1)\n",
    "\n",
    "            print('saving data')\n",
    "            flatData_df.to_csv(PROCESSED_DATA_PATH + fileName[0:18] + '_flattened.csv', index = False)\n",
    "            print('data saved')\n",
    "            print('time is: ', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0c9b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "currentDF_raw.rayCastHitsCombinedEyes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71157581",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type(CURRENT_SUBJECT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbc597",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(CURRENT_SUBJECT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86272a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file in CURRENT_SUBJECT_FOLDER:\n",
    "    CURRENT_SUBJECT_FOLDER.append(re.findall(r'\\d+', file))\n",
    "\n",
    "    # Extract all SubIDs (only one), SessionNumbers, ET_SessionNumbers (and Timestamps)\n",
    "try:\n",
    "    SubID, SessionNumbers, ET_SessionNumbers, UnixTimestamp1, UnixTimeStamp2 = map(list, zip(*folder_files))\n",
    "except:\n",
    "    print('\\tSubject '\n",
    "          + str(subject)\n",
    "          + ' Filename is not valid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c65c9d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " subject_files = sorted([file for file in CURRENT_SUBJECT_FOLDER if file.startswith(str(subject)+'_Expl_S_') and file.endswith(\"OnQuit.json\") == False],\n",
    "                        key=str.lower)\n",
    "\n",
    "# the following works as long as the data name format is as follows:\n",
    "# 'subjectID'_Expl_S_'SessionNumber'_ET_'EyeTrackingSessionNumber'_'UnixTimestamp'.json\n",
    "folder_files = list()\n",
    "\n",
    "# loop through the subject folder and save all numbers\n",
    "for file in subject_files:\n",
    "    folder_files.append(re.findall(r'\\d+', file))\n",
    "\n",
    "# Extract all SubIDs (only one), SessionNumbers, ET_SessionNumbers (and Timestamps)\n",
    "try:\n",
    "    SubID, SessionNumbers, ET_SessionNumbers, UnixTimestamp1, UnixTimeStamp2 = map(list, zip(*folder_files))\n",
    "except:\n",
    "    print('\\tSubject '\n",
    "          + str(subject)\n",
    "          + ' Filename is not valid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c03a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session_number = int(max(SessionNumbers)) # the maximum session number of the particular subject\n",
    "ET_session_number = int(max(ET_SessionNumbers)) # the maximum ET session number of the particular subject\n",
    "\n",
    "\n",
    "# print info of how many files were found\n",
    "\n",
    "print(len(SubID), ' files were found for participant ', SubID[0])\n",
    "print('A maximum of ', session_number, 'sessions were found and will be processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5003a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OneFile = \"/Volumes/SSD/Test_Exploration/9502/9502_Expl_S_01_ET_1_1641807659.90466.json\"\n",
    "with open(OneFile) as datafile:\n",
    "    try:\n",
    "        print(\"read file\")\n",
    "        dataR = '['+ datafile.read()\n",
    "        dataR = dataR[:len(dataR)] + \"]\"\n",
    "    except:\n",
    "        print(\"reading did not work\")\n",
    "\n",
    "    subject_session = json.loads(dataR)\n",
    "\n",
    "currentDF_raw = pd.json_normalize(subject_session[0]['trials'][0]['dataPoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7fb05",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "currentDF_raw.rayCastHitsCombinedEyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f6beb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "currentDF_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94717d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0803f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rayCastData_df = pd.DataFrame(np.nan,index=range(len(subject_session[0]['trials'][0]['dataPoints'])), columns= columnsRCall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d781b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# flatten the majority of the variables into currentDF data frame\n",
    "currentDF_raw = pd.json_normalize(subject_session[0]['trials'][0]['dataPoints'])\n",
    "\n",
    "# remove the 'rayCastHitsCombinedEyes' column as it still contains a nested data structure\n",
    "dataDF = currentDF_raw.drop(columns=['rayCastHitsCombinedEyes'])\n",
    "\n",
    "# create an empty data frame of the required size\n",
    "rayCastData_df = pd.DataFrame(np.nan,index=range(len(subject_session[0]['trials'][0]['dataPoints'])), columns= columnsRCall)\n",
    "\n",
    "# now loop through the individual trials and flatten the data\n",
    "for index in range(len(subject_session[0]['trials'][0]['dataPoints'])):\n",
    "    # depending on the size of the ray cast data - flatten data and appand it to currentDF data frame\n",
    "    # the variables are renamed to make the differentiation of first and second order collider hits more intuitive\n",
    "    #lengthRCData = len(subject_session[0]['trials'][0]['dataPoints'][index]['rayCastHitsCombinedEyes'][0])\n",
    "    lengthRCData = len(currentDF_raw.at[index,'rayCastHitsCombinedEyes'])\n",
    "\n",
    "\n",
    "    if lengthRCData ==0: #case: no ray cast data is available = no collider was hit\n",
    "\n",
    "        combineDF = pd.concat([emptyDF1, emptyDF2], axis=1)\n",
    "        combineDF.insert(len(combineDF.columns), 'DataRow',index)\n",
    "\n",
    "\n",
    "    elif lengthRCData == 1: # case: only one collider was hit, there is no secondary hit\n",
    "\n",
    "        pdRC1= pd.json_normalize(currentDF_raw.at[index,'rayCastHitsCombinedEyes'][0]).rename(\n",
    "            columns = {'hitObjectColliderName':'hitObjectColliderName_1',\n",
    "                       'ordinalOfHit':'ordinalOfHit_1',\n",
    "                       'hitPointOnObject.x':'hitPointOnObject.x_1',\n",
    "                       'hitPointOnObject.y':'hitPointOnObject.y_1',\n",
    "                       'hitPointOnObject.z':'hitPointOnObject.z_1',\n",
    "                       'hitObjectColliderBoundsCenter.x':'hitObjectColliderBoundsCenter.x_1',\n",
    "                       'hitObjectColliderBoundsCenter.y':'hitObjectColliderBoundsCenter.y_1',\n",
    "                       'hitObjectColliderBoundsCenter.z':'hitObjectColliderBoundsCenter.z_1'})\n",
    "        combineDF = pd.concat([pdRC1, emptyDF2], axis=1)\n",
    "        combineDF.insert(len(combineDF.columns), 'DataRow',index)\n",
    "\n",
    "    elif lengthRCData == 2: # case: two collider were hit\n",
    "\n",
    "        pdRC1= pd.json_normalize(currentDF_raw.at[index,'rayCastHitsCombinedEyes'][0]).rename(\n",
    "            columns = {'hitObjectColliderName':'hitObjectColliderName_1',\n",
    "                       'ordinalOfHit':'ordinalOfHit_1',\n",
    "                       'hitPointOnObject.x':'hitPointOnObject.x_1',\n",
    "                       'hitPointOnObject.y':'hitPointOnObject.y_1',\n",
    "                       'hitPointOnObject.z':'hitPointOnObject.z_1',\n",
    "                       'hitObjectColliderBoundsCenter.x':'hitObjectColliderBoundsCenter.x_1',\n",
    "                       'hitObjectColliderBoundsCenter.y':'hitObjectColliderBoundsCenter.y_1',\n",
    "                       'hitObjectColliderBoundsCenter.z':'hitObjectColliderBoundsCenter.z_1'})\n",
    "        pdRC2 = pd.json_normalize(currentDF_raw.at[index,'rayCastHitsCombinedEyes'][1]).rename(\n",
    "            columns = {'hitObjectColliderName':'hitObjectColliderName_2',\n",
    "                       'ordinalOfHit':'ordinalOfHit_2',\n",
    "                       'hitPointOnObject.x':'hitPointOnObject.x_2',\n",
    "                       'hitPointOnObject.y':'hitPointOnObject.y_2',\n",
    "                       'hitPointOnObject.z':'hitPointOnObject.z_2',\n",
    "                       'hitObjectColliderBoundsCenter.x':'hitObjectColliderBoundsCenter.x_2',\n",
    "                       'hitObjectColliderBoundsCenter.y':'hitObjectColliderBoundsCenter.y_2',\n",
    "                       'hitObjectColliderBoundsCenter.z':'hitObjectColliderBoundsCenter.z_2'})\n",
    "        combineDF = pd.concat([pdRC1, pdRC2], axis=1)\n",
    "    else:\n",
    "        print('!!!an exception occured in the ray cast data flattening in trial ', index)\n",
    "\n",
    "        # now add the new data row to the data overview\n",
    "        # rayCastData_df = [rayCastData_df]\n",
    "\n",
    "\n",
    "    rayCastData_df.loc[index] = combineDF.loc[0]\n",
    "\n",
    "    flatData_df = pd.concat([dataDF,rayCastData_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7377f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combineDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecece5d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rayCastData_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22714669",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reduced_data = currentDF_raw.loc[:, cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c5ae8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e403a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reduced_data.explode('rayCastHitsCombinedEyes', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c097c3b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reduced_data.rayCastHitsCombinedEyes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d578831",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exploded = reduced_data['rayCastHitsCombinedEyes'].explode().apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9beee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exploded.groupby(['hitObjectColliderName', 'hitColliderType']).count()['ordinalOfHit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412403b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba347c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

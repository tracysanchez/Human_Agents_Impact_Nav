library(lubridate)     # Working with dates and timestamps
library(zoo)           # Required for time-series data
library(tidyverse)     # Meta-package (includes dplyr, ggplot2, tidyr, etc.)
library(tidyr)         # Data tidying functions
library(brms)          # Bayesian regression modeling via Stan
library(stringr)       # String manipulation (used for ID extraction)
library(mice)          # For missing data
library(bridgesampling)
HumanA_Fixations <- read.csv("/Volumes/TwoTeras/2_DataSets_Experiments_1_2/BehavioralData_Fixations_Wide.csv", sep =",")
head(HumanA_Fixations)
unique(HumanA_Fixations$SubjectID)
Entropy <- read.csv("/Volumes/TwoTeras/1_Experiment_2/Entropy_Results/grouped_for_LMM_Chao_Shen_Normalized.csv", sep =",")
# Ensure Entropy is a data frame or tibble
Entropy <- as.data.frame(Entropy)
# Drop columns X and Experiment using base R
Entropy <- Entropy[, !(names(Entropy) %in% c("X", "Experiment"))]
# View the updated dataset
head(Entropy)
unique(Entropy$Participant_ID)
# Rename columns in the Entropy dataset
Entropy <- Entropy %>%
rename(
avatar_ID=  Agent_ID,
SubjectID= Participant_ID
)
Entropy <- Entropy %>%
mutate(SubjectID = as.integer(SubjectID))
# Perform concatenation based on avatar_ID and SubjectID
Merged_Data <- HumanA_Fixations %>%
inner_join(Entropy, by = c("avatar_ID", "SubjectID"))
# View the merged dataset
head(Merged_Data)
nMerged_Data <- Merged_Data %>%      # Recoding variables
mutate(
ContextEffect = case_when(
Context == "False" ~ -0.5,
Context == "True" ~ 0.5,
TRUE ~ NaN
),
AgentPresence = case_when(
AvatarPresenceCategory == "Omitted" ~ -0.5,
AvatarPresenceCategory == "Present" ~ 0.5,
TRUE ~ NaN
),
Agent_Action_level = case_when(
Agent_Category == "Passive" ~ -0.5,
Agent_Category == "Active" ~ 0.5,
TRUE ~ NaN
),
Experiment = case_when(
Experiment == 1 ~ -0.5,
Experiment == 2 ~ 0.5,
TRUE ~ NaN
),
# Define Agent_Type variable for contrast coding
Agent_Type = case_when(
Agent_Action_level == -0.5 ~ 0,   # Passive -> Acontextual
Agent_Action_level == 0.5 & Experiment == -0.5 ~ 0.5,  # Active + Experiment 1 -> Congruent
Agent_Action_level == 0.5 & Experiment == 0.5 ~ -0.5,  # Active + Experiment 2 -> Incongruent
TRUE ~ NaN
)
) %>%
# Convert numeric variables to factors and set "Acontextual" as the reference level
mutate(
ContextEffectf = factor(ContextEffect, levels = c(-0.5, 0.5), labels = c('Residential', 'Public')),
AgentPresencef = factor(AgentPresence, levels = c(-0.5, 0.5), labels = c('Omitted', 'Displayed')),
Agent_Action_levelf = factor(Agent_Action_level, levels = c(-0.5, 0.5), labels = c('Passive', 'Active')),
Experimentf = factor(Experiment, levels = c(-0.5, 0.5), labels = c('Experiment 1', 'Experiment 2')),
Agent_Typef = factor(Agent_Type, levels = c(0, 0.5, -0.5), labels = c('Acontextual', 'Congruent', 'Incongruent'))
) %>%
# Ensure "Acontextual" is the reference level for contrast coding
mutate(Agent_Typef = relevel(Agent_Typef, ref = "Acontextual")) %>%
# Center dwelling time variables
mutate(
Dwelling_Time_Building_Gaze_Centered = Dwelling_Time_Building_Gaze - mean(Dwelling_Time_Building_Gaze, na.rm = TRUE),
Dwelling_Time_Agent_Gaze_Centered = Dwelling_Time_Agent_Gaze - mean(Dwelling_Time_Agent_Gaze, na.rm = TRUE)
)
df <- nMerged_Data %>%
filter(complete.cases(.))
p <- ggplot(df, aes(x = AbsolutError, fill = Agent_Action_levelf)) +
geom_histogram(aes(group = Agent_Action_levelf),
position = "identity",
alpha = 0.5,
binwidth = 10) +
facet_grid(cols = vars(ContextEffectf)) +
theme_bw()
# Print the plot
p
colSums(is.na(Merged_Data))
imputed_data <- mice(Merged_Data, method = "pmm", m = 5)
bayesian_performance_model <- brm(
AbsolutError ~ Dwelling_Time_Building_Gaze_Centered + Dwelling_Time_Agent_Gaze_Centered +
ContextEffectf + Agent_Type*median +
(1 | SubjectID) + (1 | PointingTaskStartingLocations),
data = nMerged_Data,
family = Gamma(link = "log"),  # Use lognormal or another appropriate family
cores = 4, chains = 4, iter = 4000, warmup = 1000,
save_pars = save_pars(all = TRUE)
)
summary(bayesian_performance_model)
bayesian_performance_model <- brm(
AbsolutError ~ Dwelling_Time_Building_Gaze_Centered + Dwelling_Time_Agent_Gaze_Centered +
ContextEffectf + Agent_Type + median +
(1 | SubjectID) + (1 | PointingTaskStartingLocations),
data = nMerged_Data,
family = Gamma(link = "log"),  # Use lognormal or another appropriate family
cores = 4, chains = 4, iter = 4000, warmup = 1000,
save_pars = save_pars(all = TRUE)
)
summary(bayesian_performance_model)
# Remove one predictor at a time
model_no_Building <- update(bayesian_performance_model, formula = . ~ . - Dwelling_Time_Building_Gaze_Centered)
# Remove one predictor at a time
model_no_Building <- update(bayesian_performance_model, formula = . ~ . - Dwelling_Time_Building_Gaze_Centered,
cores = 4)
model_no_Agent <- update(bayesian_performance_model, formula = . ~ . - Dwelling_Time_Agent_Gaze_Centered,
cores = 4)
model_no_Context <- update(bayesian_performance_model, formula = . ~ . - ContextEffectf,
cores = 4)
model_no_AgentType <- update(bayesian_performance_model, formula = . ~ . - Agent_Type,
cores = 4)
# Remove one predictor at a time
#model_no_Building <- update(bayesian_performance_model, formula = . ~ . - Dwelling_Time_Building_Gaze_Centered,
#cores = 4)
#model_no_Agent <- update(bayesian_performance_model, formula = . ~ . - Dwelling_Time_Agent_Gaze_Centered,
#cores = 4)
#model_no_Context <- update(bayesian_performance_model, formula = . ~ . - ContextEffectf,
#cores = 4)
model_no_AgentType <- update(bayesian_performance_model, formula = . ~ . - Agent_Type,
cores = 4)
model_no_Median <- update(bayesian_performance_model, formula = . ~ . - median,
cores = 4)
# Compute marginal likelihoods using bridge sampling
bridge_full <- bridge_sampler(bayesian_performance_model)
bridge_Building <- bridge_sampler(model_no_Building)
bridge_Agent <- bridge_sampler(model_no_Agent)
bridge_Context <- bridge_sampler(model_no_Context)
bridge_AgentType <- bridge_sampler(model_no_AgentType)
bridge_Median <- bridge_sampler(model_no_Median)
# Compute Bayes Factors (BF) against the full model
bf_Building <- bf(bridge_full, bridge_Building)
bf_Agent <- bf(bridge_full, bridge_Agent)
bf_Context <- bf(bridge_full, bridge_Context)
bf_AgentType <- bf(bridge_full, bridge_AgentType)
bf_Median <- bf(bridge_full, bridge_Median)
# Print Bayes Factor results
print(bf_Building)
print(bf_Agent)
print(bf_Context)
print(bf_AgentType)
print(bf_Median)
# Create a dataframe for Bayes Factors
bf_data <- data.frame(
Predictor = c("Building_Gaze", "Agent_Gaze", "ContextEffect", "Agent_Type", "Median"),
BayesFactor = c(as.numeric(bf_Building$bf), as.numeric(bf_Agent$bf), as.numeric(bf_Context$bf),
as.numeric(bf_AgentType$bf), as.numeric(bf_Median$bf))
)
# Log transform for readability
bf_data$LogBF <- log10(bf_data$BayesFactor)
# Classify evidence strength based on Jeffreys' Bayes Factor interpretation
bf_data$Category <- ifelse(bf_data$BayesFactor > 30, "Strong Evidence",
ifelse(bf_data$BayesFactor > 3, "Moderate Evidence",
ifelse(bf_data$BayesFactor > 1, "Weak Evidence", "Against Inclusion")))
# Create a bar plot to visualize Bayes Factors
ggplot(bf_data, aes(x = reorder(Predictor, LogBF), y = LogBF, fill = Category)) +
geom_bar(stat = "identity") +
geom_text(aes(label = round(BayesFactor, 2)), hjust = 1.2, color = "white", size = 4) +
scale_fill_manual(values = c("Strong Evidence" = "darkred", "Moderate Evidence" = "orange",
"Weak Evidence" = "yellow", "Against Inclusion" = "blue")) +
labs(title = "Bayes Factors for Predictors",
subtitle = "Log-transformed Bayes Factors (BF > 1 favors inclusion, BF < 1 favors exclusion)",
x = "Predictor",
y = "Log10(Bayes Factor)") +
theme_minimal() +
coord_flip()  # Flips the axes for readability
# Create a dataframe for Bayes Factors with updated predictor labels
bf_data <- data.frame(
Predictor = c("Building Type", "Dwell on Building", "Agent Type", "Entropy", "Dwell Agent"),
BayesFactor = c(as.numeric(bf_Context$bf), as.numeric(bf_Building$bf), as.numeric(bf_AgentType$bf),
as.numeric(bf_Median$bf), as.numeric(bf_Agent$bf))
)
# Log transform for readability
bf_data$LogBF <- log10(bf_data$BayesFactor)
# Classify evidence strength
bf_data$Category <- ifelse(bf_data$BayesFactor > 30, "Strong Evidence",
ifelse(bf_data$BayesFactor > 3, "Moderate Evidence",
ifelse(bf_data$BayesFactor > 1, "Weak Evidence", "Against Inclusion")))
# Create a bar plot with the updated y-axis tick labels
ggplot(bf_data, aes(x = reorder(Predictor, LogBF), y = LogBF, fill = Category)) +
geom_bar(stat = "identity") +
geom_text(aes(label = round(BayesFactor, 2)), hjust = 1.2, color = "white", size = 4) +
scale_fill_manual(values = c("Strong Evidence" = "darkred", "Moderate Evidence" = "orange",
"Weak Evidence" = "yellow", "Against Inclusion" = "blue")) +
labs(title = "Bayes Factors for Predictors",
subtitle = "Log-transformed Bayes Factors (BF > 1 favors inclusion, BF < 1 favors exclusion)",
x = "Predictor",
y = "Log10(Bayes Factor)") +
theme_minimal() +
coord_flip()  # Flips the axes for readability
summery(bayesian_performance_model)
summary(bayesian_performance_model)
save.image("~/Bayes_Performance.RData")
library(dplyr)
# Prepare df_post for modeling Post_Entropy only
df_post <- df_combined %>%
mutate(
ID = factor(ID),
Session = factor(Session),
Condition = factor(Condition, levels = c("Pre", "Post")),
Agent_Type = factor(Agent_Type),
Building = factor(Building)
) %>%
arrange(ID, Session, Event_Index)  # Ensure correct chronological order
# Load necessary packages
library(dplyr)
library(readr)
library(stringr)
# Define directories for each experiment
exp1_dir <- "/Volumes/TwoTeras/0_Experiment_1/Entropy_Results/Window/entropy_results/CausalImpact/"
exp2_dir <- "/Volumes/TwoTeras/1_Experiment_2/Entropy_Results/Window/entropy_results/CausalImpact/"
labels <- read.csv("/Volumes/TwoTeras/Resources/AgentCoordinates_short_exp2.csv")
# List all CSV files in each directory
exp1_files <- list.files(exp1_dir, pattern = "*.csv", full.names = TRUE)
exp2_files <- list.files(exp2_dir, pattern = "*.csv", full.names = TRUE)
# Function to extract first two digits from Collider_Name
extract_first_two_digits <- function(name) {
num <- str_extract(name, "^\\d{2}")  # Extract first two digits
as.numeric(num)  # Convert to numeric
}
# Load and process Experiment 1
exp1_list <- lapply(exp1_files, read_csv)
Experiment1 <- bind_rows(exp1_list) %>%
mutate(Experiment = 1,
Collider_Number = extract_first_two_digits(Collider_Name),  # Extract first two digits
Building = ifelse(Collider_Number <= 28, "Public", "Residential"),  # Assign 'Building'
Building_Effect = ifelse(Building == "Public", 0.5, -0.5))  # Apply effect coding
# Ensure Collider_Number exists before removing it
if ("Collider_Number" %in% colnames(Experiment1)) {
Experiment1 <- Experiment1 %>% dplyr::select(-Collider_Number)
}
# Load and process Experiment 2
exp2_list <- lapply(exp2_files, read_csv)
Experiment2 <- bind_rows(exp2_list) %>%
mutate(Experiment = 2,
Collider_Number = extract_first_two_digits(Collider_Name)) %>%
left_join(labels, by = c("Collider_Name" = "AvatarName")) %>%  # Match agent names
mutate(Building = ifelse(Context == TRUE, "Public", "Residential"),
Building_Effect = ifelse(Building == "Public", 0.5, -0.5)) %>%  # Apply effect coding
dplyr::select(all_of(names(Experiment1)))  # Ensure same columns as Experiment1
# Combine both experiments
df_combined <- bind_rows(Experiment1, Experiment2)
# Check final dataset structure
glimpse(df_combined)
# View first rows to confirm changes
head(df_combined)
# Load necessary library for string manipulation
# Split Participant_ID into ID and Session
df_combined <- df_combined %>%
mutate(
ID = str_extract(Participant_ID, "^[^_]+"),  # Extract part before '_'
Session = str_extract(Participant_ID, "(?<=_).*")  # Extract part after '_'
)
# Create Agent_Type based on Collider_Name
df_combined <- df_combined %>%
mutate(
Agent_Type = ifelse(str_detect(Collider_Name, "Cma"), "Active", "Passive"),
Agent_Effect = ifelse(Agent_Type == "Active", 0.5, -0.5)  # Effect coding
)
# Convert new variables to factors
df_combined <- df_combined %>%
mutate(
ID = as.factor(ID),
Session = as.factor(Session),
Agent_Type = as.factor(Agent_Type)
)
df_combined <- df_combined %>%
mutate(
# Define Match (Congruency) using the original rule
Match = ifelse((Experiment == 1 & Agent_Effect == 0.5), 0.5, -0.5),
# Effect coding for Experiment
Experiment = case_when(
Experiment == 1 ~ -0.5,
Experiment == 2 ~ 0.5,
TRUE ~ NaN  # Should never occur but ensures robustness
)
)
# Create Event_Index before reshaping
df_combined <- df_combined %>%
arrange(ID, Session, Gaze_Time) %>%  # Ensure correct chronological order
group_by(ID, Session) %>%
mutate(Event_Index = row_number()) %>%  # Assigns a single index per gaze event
ungroup()
# Display first few rows to verify changes
head(df_combined)
library(dplyr)
# Create two subsets
df_above_60 <- df_combined %>% filter(Event_Index > 60)
df_below_60 <- df_combined %>% filter(Event_Index <= 60)
# Total number of rows
total_rows <- nrow(df_combined)
# Number of rows in each category
above_60 <- nrow(df_above_60)
below_60 <- nrow(df_below_60)
# Calculate percentages
above_60_pct <- (above_60 / total_rows) * 100
below_60_pct <- (below_60 / total_rows) * 100
# Print results
cat("Percentage of Event_Index > 60:", round(above_60_pct, 2), "%\n")
cat("Percentage of Event_Index ≤ 60:", round(below_60_pct, 2), "%\n")
# Check dimensions of the kept dataframes
dim(df_above_60)  # Shows dimensions of rows and columns
dim(df_below_60)  # Shows dimensions of rows and columns
View(df_below_60)
View(df_below_60)
# Custom contrast coding matrix
custom_contrasts <- matrix(c(-2/3, 1/3, 1/3,  # Contrast 1: Acontextual vs. (Congruent & Incongruent)
0, -0.5, 0.5),   # Contrast 2: Congruent vs. Incongruent
ncol = 2)
rownames(custom_contrasts) <- c("Acontextual", "Congruent", "Incongruent")
colnames(custom_contrast) <- c("Acontextual_vs_Others", "Congruent_vs_Incongruent")
# Custom contrast coding matrix
custom_contrasts <- matrix(c(-2/3, 1/3, 1/3,  # Contrast 1: Acontextual vs. (Congruent & Incongruent)
0, -0.5, 0.5),   # Contrast 2: Congruent vs. Incongruent
ncol = 2)
rownames(custom_contrasts) <- c("Acontextual", "Congruent", "Incongruent")
colnames(custom_contrasts) <- c("Acontextual_vs_Others", "Congruent_vs_Incongruent")
# Assign contrasts
contrasts(df_post$Agent_Type)
# Custom contrast coding matrix
custom_contrasts <- matrix(c(-2/3, 1/3, 1/3,  # Contrast 1: Acontextual vs. (Congruent & Incongruent)
0, -0.5, 0.5),   # Contrast 2: Congruent vs. Incongruent
ncol = 2)
rownames(custom_contrasts) <- c("Acontextual", "Congruent", "Incongruent")
colnames(custom_contrasts) <- c("Acontextual_vs_Others", "Congruent_vs_Incongruent")
# Assign contrasts
contrasts(df_below_60$Agent_Type)
unique(df_below_60$Agent_Type)
# Load necessary libraries
library(CausalImpact)  # For causal inference and impact analysis
library(dplyr)         # Data manipulation
library(ggplot2)       # Visualization
library(readr)         # Reading CSV files
library(lubridate)     # Working with dates and timestamps
library(zoo)           # Required for time-series data
library(tidyverse)     # Meta-package (includes dplyr, ggplot2, tidyr, etc.)
library(tidyr)         # Data tidying functions
library(brms)          # Bayesian regression modeling via Stan
library(stringr)       # String manipulation (used for ID extraction)
# Load necessary packages
library(dplyr)
library(readr)
library(stringr)
# Define directories for each experiment
exp1_dir <- "/Volumes/TwoTeras/0_Experiment_1/Entropy_Results/Window/entropy_results/CausalImpact/"
exp2_dir <- "/Volumes/TwoTeras/1_Experiment_2/Entropy_Results/Window/entropy_results/CausalImpact/"
labels <- read.csv("/Volumes/TwoTeras/Resources/AgentCoordinates_short_exp2.csv")
# List all CSV files in each directory
exp1_files <- list.files(exp1_dir, pattern = "*.csv", full.names = TRUE)
exp2_files <- list.files(exp2_dir, pattern = "*.csv", full.names = TRUE)
# Function to extract first two digits from Collider_Name
extract_first_two_digits <- function(name) {
num <- str_extract(name, "^\\d{2}")  # Extract first two digits
as.numeric(num)  # Convert to numeric
}
# Load and process Experiment 1
exp1_list <- lapply(exp1_files, read_csv)
Experiment1 <- bind_rows(exp1_list) %>%
mutate(Experiment = 1,
Collider_Number = extract_first_two_digits(Collider_Name),  # Extract first two digits
Building = ifelse(Collider_Number <= 28, "Public", "Residential"),  # Assign 'Building'
Building_Effect = ifelse(Building == "Public", 0.5, -0.5))  # Apply effect coding
# Ensure Collider_Number exists before removing it
if ("Collider_Number" %in% colnames(Experiment1)) {
Experiment1 <- Experiment1 %>% dplyr::select(-Collider_Number)
}
# Load and process Experiment 2
exp2_list <- lapply(exp2_files, read_csv)
Experiment2 <- bind_rows(exp2_list) %>%
mutate(Experiment = 2,
Collider_Number = extract_first_two_digits(Collider_Name)) %>%
left_join(labels, by = c("Collider_Name" = "AvatarName")) %>%  # Match agent names
mutate(Building = ifelse(Context == TRUE, "Public", "Residential"),
Building_Effect = ifelse(Building == "Public", 0.5, -0.5)) %>%  # Apply effect coding
dplyr::select(all_of(names(Experiment1)))  # Ensure same columns as Experiment1
# Combine both experiments
df_combined <- bind_rows(Experiment1, Experiment2)
# Check final dataset structure
glimpse(df_combined)
# View first rows to confirm changes
head(df_combined)
# Split Participant_ID into ID and Session
df_combined <- df_combined %>%
mutate(
ID = str_extract(Participant_ID, "^[^_]+"),  # Extract participant ID
Session = str_extract(Participant_ID, "(?<=_).*")  # Extract session number
)
# Create Agent_Type as a clear factor with 3 categories
df_combined <- df_combined %>%
mutate(
Agent_Type = case_when(
Agent_Effect == -0.5 ~ "Acontextual",                          # Passive agents
Agent_Effect == 0.5 & Experiment == -0.5 ~ "Congruent",        # Active agents in Experiment 1
Agent_Effect == 0.5 & Experiment == 0.5 ~ "Incongruent",       # Active agents in Experiment 2
TRUE ~ NA_character_                                            # Shouldn't occur but for robustness
)
)
# Load necessary library for string manipulation
library(dplyr)
library(stringr)
# Split Participant_ID into ID and Session
df_combined <- df_combined %>%
mutate(
ID = str_extract(Participant_ID, "^[^_]+"),  # Extract part before '_'
Session = str_extract(Participant_ID, "(?<=_).*")  # Extract part after '_'
)
# Create Agent_Type and initial Agent_Effect based on Collider_Name
df_combined <- df_combined %>%
mutate(
Agent_Type = ifelse(str_detect(Collider_Name, "Cma"), "Active", "Passive"),
Agent_Effect = ifelse(Agent_Type == "Active", 0.5, -0.5)  # Initial effect coding
)
# Convert new variables to factors and explicitly define Agent_Type levels (Acontextual, Congruent, Incongruent)
df_combined <- df_combined %>%
mutate(
ID = as.factor(ID),
Session = as.factor(Session),
Agent_Type = factor(case_when(
Agent_Effect == -0.5 ~ "Acontextual",
Agent_Effect == 0.5 & Experiment == -0.5 ~ "Congruent",
Agent_Effect == 0.5 & Experiment == 0.5 ~ "Incongruent",
TRUE ~ NA_character_
), levels = c("Acontextual", "Congruent", "Incongruent"))
)
# Apply the corrected contrasts (each condition against Acontextual separately)
custom_contrasts <- matrix(c(-1, -1,   # Acontextual (baseline)
1,  0,   # Congruent vs. Acontextual
0,  1),  # Incongruent vs. Acontextual
ncol = 2)
rownames(custom_contrasts) <- c("Acontextual", "Congruent", "Incongruent")
colnames(custom_contrasts) <- c("Congruent_vs_Acontextual", "Incongruent_vs_Acontextual")
contrasts(df_combined$Agent_Type) <- custom_contrasts
# Continue with additional effect coding and Event_Index creation
df_combined <- df_combined %>%
mutate(
# Define Match (Congruency) using the original rule
Match = ifelse((Experiment == 1 & Agent_Effect == 0.5), 0.5, -0.5),
# Effect coding for Experiment
Experiment = case_when(
Experiment == 1 ~ -0.5,
Experiment == 2 ~ 0.5,
TRUE ~ NaN
)
) %>%
arrange(ID, Session, Gaze_Time) %>%  # Chronological order
group_by(ID, Session) %>%
mutate(Event_Index = row_number()) %>%
ungroup()
# Display first few rows to verify changes
head(df_combined)
library(dplyr)
# Create two subsets
df_above_60 <- df_combined %>% filter(Event_Index > 60)
df_below_60 <- df_combined %>% filter(Event_Index <= 60)
# Total number of rows
total_rows <- nrow(df_combined)
# Number of rows in each category
above_60 <- nrow(df_above_60)
below_60 <- nrow(df_below_60)
# Calculate percentages
above_60_pct <- (above_60 / total_rows) * 100
below_60_pct <- (below_60 / total_rows) * 100
# Print results
cat("Percentage of Event_Index > 60:", round(above_60_pct, 2), "%\n")
cat("Percentage of Event_Index ≤ 60:", round(below_60_pct, 2), "%\n")
# Check dimensions of the kept dataframes
dim(df_above_60)  # Shows dimensions of rows and columns
dim(df_below_60)  # Shows dimensions of rows and columns
# Reshape the data into long format
df_long <- df_below_60 %>%
pivot_longer(
cols = c(Pre_Entropy, Post_Entropy),
names_to = "Pre_Post",
values_to = "Entropy"
) %>%
mutate(
# Convert Condition to a factor
Pre_Post = factor(Pre_Post, levels = c("Pre_Entropy", "Post_Entropy")),
# Apply effect coding: -0.5 for Pre_Entropy, 0.5 for Post_Entropy
Pre_Post_Effect = ifelse(Pre_Post == "Pre_Entropy", -0.5, 0.5)
)
# Display first few rows to verify changes
head(df_long)
library(brms)
# Bayesian hierarchical model predicting Post_Entropy
bayesian_post_entropy_model <- brm(
Post_Entropy ~ Building_Effect + Agent_Effect + Match + s(Event_Index, k = 5) + (1 | ID/Session),
data = df_below_60,
family = gaussian(),
cores = parallel::detectCores(),
chains = 4, iter = 4000, warmup = 1000,
save_pars = save_pars(all = TRUE)
)
library(brms)
# Bayesian hierarchical model predicting Post_Entropy
bayesian_post_entropy_model <- brm(
Post_Entropy ~ Building_Effect + Agent_Effect + Match + s(Event_Index, k = 5) + (1 | ID/Session),
data = df_below_60,
family = gaussian(),
cores = parallel::detectCores(),
chains = 4, iter = 4000, warmup = 1000,
save_pars = save_pars(all = TRUE)
)

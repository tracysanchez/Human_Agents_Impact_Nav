ContextEffectf = factor(ctx_lvls[1],   levels = ctx_lvls)
),
re_formula = NA, summary = FALSE
)
)[1]
n_y <- dim(
posterior_epred(
fit_Y_int,
newdata = nd_Y(agent_lvls[1], gte = 0.5, dwA = 1, dwB = 1, ctx = ctx_lvls[1]),
re_formula = NA, summary = FALSE
)
)[1]
n_draws <- min(4000L, n_med, n_y)
results <- vector("list", length(contrasts))
for (i in seq_along(contrasts)) {
a0 <- contrasts[[i]][1]  # baseline
a1 <- contrasts[[i]][2]  # treatment
message("Processing (joint mediators): ", a1, " vs ", a0)
eff <- purrr::map_dfr(seq_len(n_draws), function(d) {
# Mediators under a0 and a1 (JOINT draw alignment via same 'd')
med_a0 <- pred_mediators_joint(ffit_med_mv, a0, d)
med_a1 <- pred_mediators_joint(ffit_med_mv, a1, d)
m1_a0 <- med_a0$m1; m2_a0 <- med_a0$m2; m3_a0 <- med_a0$m3
m1_a1 <- med_a1$m1; m2_a1 <- med_a1$m2; m3_a1 <- med_a1$m3
# Potential outcomes (Gamma mean on response scale), averaged over context
Y00 <- predY_pop(fit_Y_int, a0, m1_a0, m2_a0, m3_a0, d)  # baseline
Y10 <- predY_pop(fit_Y_int, a1, m1_a0, m2_a0, m3_a0, d)  # direct (A switches; Ms fixed at a0)
# Single-path indirects
Y01_m1  <- predY_pop(fit_Y_int, a0, m1_a1, m2_a0, m3_a0, d)  # via GTE only
Y01_m2  <- predY_pop(fit_Y_int, a0, m1_a0, m2_a1, m3_a0, d)  # via Dwell_Agent only
Y01_m3  <- predY_pop(fit_Y_int, a0, m1_a0, m2_a0, m3_a1, d)  # via Dwell_Building only
Y01_all <- predY_pop(fit_Y_int, a0, m1_a1, m2_a1, m3_a1, d)  # joint mediator change
# Treatment with its own mediators
Y11 <- predY_pop(fit_Y_int, a1, m1_a1, m2_a1, m3_a1, d)
# Effects (response scale)
NDE       <- Y10 - Y00
NIE_GTE   <- Y01_m1 - Y00
NIE_DW_A  <- Y01_m2 - Y00
NIE_DW_B  <- Y01_m3 - Y00
NIE_joint <- (Y01_all - Y00) - (NIE_GTE + NIE_DW_A + NIE_DW_B)
TE        <- Y11 - Y00
tibble::tibble(.draw = d, comparison = paste(a1,"vs",a0),
NDE, NIE_GTE, NIE_DW_A, NIE_DW_B, NIE_joint, TE)
})
results[[i]] <- eff
}
# ============================================================
# (E) Counterfactual loop using JOINT mediator predictions
#     (clean, no alias; brms resp names handled)
# ============================================================
# brms sanitizes response names by removing non-alphanumeric chars.
resp_name <- function(x) gsub("[^A-Za-z0-9]", "", x)
resp <- list(
gte = resp_name("GTE_median_adj"),              # typically "GTEmedianadj"
dwa = resp_name("Dwelling_Time_Agent_Gaze"),    # "DwellingTimeAgentGaze"
dwb = resp_name("Dwelling_Time_Building_Gaze")  # "DwellingTimeBuildingGaze"
)
# Joint mediator predictions under agent level 'agent' at draw 'draw'
# - Posterior means on the RESPONSE scale
# - Averaged over ContextEffectf with weights ctx_w
pred_mediators_joint <- function(ffit_med_mv, agent, draw) {
new_ctx <- dplyr::bind_rows(lapply(ctx_lvls, function(ctx) {
tibble::tibble(
Agent_Typef    = factor(agent, levels = agent_lvls),
ContextEffectf = factor(ctx,    levels = ctx_lvls)
)
}))
gte_draws <- posterior_epred(
ffit_med_mv, resp = resp$gte,
newdata = new_ctx, re_formula = NA, summary = FALSE
)
dwa_draws <- posterior_epred(
ffit_med_mv, resp = resp$dwa,
newdata = new_ctx, re_formula = NA, summary = FALSE
)
dwb_draws <- posterior_epred(
ffit_med_mv, resp = resp$dwb,
newdata = new_ctx, re_formula = NA, summary = FALSE
)
m1 <- as.numeric(gte_draws[draw, ] %*% ctx_w)  # GTE
m2 <- as.numeric(dwa_draws[draw, ] %*% ctx_w)  # Dwell_Agent
m3 <- as.numeric(dwb_draws[draw, ] %*% ctx_w)  # Dwell_Building
list(m1 = m1, m2 = m2, m3 = m3)
}
# Contrasts to evaluate
contrasts <- list(
c("Acontextual","Congruent"),
c("Acontextual","Incongruent"),
c("Congruent","Incongruent")
)
# Shared number of draws across mediator and outcome models
n_med <- dim(
posterior_epred(
ffit_med_mv,
resp = resp$gte,
newdata = tibble::tibble(
Agent_Typef    = factor(agent_lvls[1], levels = agent_lvls),
ContextEffectf = factor(ctx_lvls[1],   levels = ctx_lvls)
),
re_formula = NA, summary = FALSE
)
)[1]
n_y <- dim(
posterior_epred(
fit_Y_int,
newdata = nd_Y(agent_lvls[1], gte = 0.5, dwA = 1, dwB = 1, ctx = ctx_lvls[1]),
re_formula = NA, summary = FALSE
)
)[1]
n_draws <- min(4000L, n_med, n_y)
results <- vector("list", length(contrasts))
for (i in seq_along(contrasts)) {
a0 <- contrasts[[i]][1]  # baseline
a1 <- contrasts[[i]][2]  # treatment
message("Processing (joint mediators): ", a1, " vs ", a0)
eff <- purrr::map_dfr(seq_len(n_draws), function(d) {
# Mediators under a0 and a1 (JOINT draw alignment via same 'd')
med_a0 <- pred_mediators_joint(ffit_med_mv, a0, d)
med_a1 <- pred_mediators_joint(ffit_med_mv, a1, d)
m1_a0 <- med_a0$m1; m2_a0 <- med_a0$m2; m3_a0 <- med_a0$m3
m1_a1 <- med_a1$m1; m2_a1 <- med_a1$m2; m3_a1 <- med_a1$m3
# Potential outcomes (Gamma mean on response scale), averaged over context
Y00 <- predY_pop(fit_Y_int, a0, m1_a0, m2_a0, m3_a0, d)  # baseline
Y10 <- predY_pop(fit_Y_int, a1, m1_a0, m2_a0, m3_a0, d)  # direct (A switches; Ms fixed at a0)
# Single-path indirects
Y01_m1  <- predY_pop(fit_Y_int, a0, m1_a1, m2_a0, m3_a0, d)  # via GTE only
Y01_m2  <- predY_pop(fit_Y_int, a0, m1_a0, m2_a1, m3_a0, d)  # via Dwell_Agent only
Y01_m3  <- predY_pop(fit_Y_int, a0, m1_a0, m2_a0, m3_a1, d)  # via Dwell_Building only
Y01_all <- predY_pop(fit_Y_int, a0, m1_a1, m2_a1, m3_a1, d)  # joint mediator change
# Treatment with its own mediators
Y11 <- predY_pop(fit_Y_int, a1, m1_a1, m2_a1, m3_a1, d)
# Effects (response scale)
NDE       <- Y10 - Y00
NIE_GTE   <- Y01_m1 - Y00
NIE_DW_A  <- Y01_m2 - Y00
NIE_DW_B  <- Y01_m3 - Y00
NIE_joint <- (Y01_all - Y00) - (NIE_GTE + NIE_DW_A + NIE_DW_B)
TE        <- Y11 - Y00
tibble::tibble(.draw = d, comparison = paste(a1,"vs",a0),
NDE, NIE_GTE, NIE_DW_A, NIE_DW_B, NIE_joint, TE)
})
results[[i]] <- eff
}
combined <- dplyr::bind_rows(results)
# Decomposition check: TE ≈ NDE + NIEs + NIE_joint
check <- combined |>
dplyr::mutate(diff = TE - (NDE + NIE_GTE + NIE_DW_A + NIE_DW_B + NIE_joint)) |>
dplyr::group_by(comparison) |>
dplyr::summarise(mean_diff = mean(diff), max_abs_diff = max(abs(diff)), .groups = "drop")
print(check)
# 89% summaries
summary_df <- combined |>
tidyr::pivot_longer(c(NDE, NIE_GTE, NIE_DW_A, NIE_DW_B, NIE_joint, TE),
names_to = "effect", values_to = "value") |>
dplyr::group_by(comparison, effect) |>
dplyr::summarise(
mean  = mean(value),
lower = quantile(value, 0.055),
upper = quantile(value, 0.945),
prob_negative = mean(value < 0),
.groups = "drop"
)
print(summary_df)
save.image("~/Library/CloudStorage/OneDrive-Persönlich/PhD/DataAnalysis/DataAnalysis/Joining_FinalData/meidation.RData")
# Load necessary libraries
library(CausalImpact)  # For causal inference and impact analysis
library(dplyr)         # Data manipulation
library(ggplot2)       # Visualization
library(readr)         # Reading CSV files
library(lubridate)     # Working with dates and timestamps
library(zoo)           # Required for time-series data
library(tidyverse)     # Meta-package (includes dplyr, ggplot2, tidyr, etc.)
library(tidyr)         # Data tidying functions
library(brms)          # Bayesian regression modeling via Stan
library(stringr)       # String manipulation (used for ID extraction)
# Define directories for each experiment
exp1_dir <- "/Volumes/TwoTeras/0_Experiment_1/Entropy_Results/Window/entropy_results/CausalImpact/"
exp2_dir <- "/Volumes/TwoTeras/1_Experiment_2/Entropy_Results/Window/entropy_results/CausalImpact/"
labels <- read.csv("/Volumes/TwoTeras/Resources/AgentCoordinates_short_exp2.csv")
# List all CSV files in each directory
exp1_files <- list.files(exp1_dir, pattern = "*.csv", full.names = TRUE)
exp2_files <- list.files(exp2_dir, pattern = "*.csv", full.names = TRUE)
# Function to extract first two digits from Collider_Name
extract_first_two_digits <- function(name) {
num <- str_extract(name, "^\\d{2}")  # Extract first two digits
as.numeric(num)  # Convert to numeric
}
# Load and process Experiment 1
exp1_list <- lapply(exp1_files, read_csv)
Experiment1 <- bind_rows(exp1_list) %>%
mutate(Experiment = 1,
Collider_Number = extract_first_two_digits(Collider_Name),  # Extract first two digits
Building = ifelse(Collider_Number <= 28, "Public", "Residential"),  # Assign 'Building'
Building_Effect = ifelse(Building == "Public", 0.5, -0.5))  # Apply effect coding
# Ensure Collider_Number exists before removing it
if ("Collider_Number" %in% colnames(Experiment1)) {
Experiment1 <- Experiment1 %>% dplyr::select(-Collider_Number)
}
# Load and process Experiment 2
exp2_list <- lapply(exp2_files, read_csv)
Experiment2 <- bind_rows(exp2_list) %>%
mutate(Experiment = 2,
Collider_Number = extract_first_two_digits(Collider_Name)) %>%
left_join(labels, by = c("Collider_Name" = "AvatarName")) %>%  # Match agent names
mutate(Building = ifelse(Context == TRUE, "Public", "Residential"),
Building_Effect = ifelse(Building == "Public", 0.5, -0.5)) %>%  # Apply effect coding
dplyr::select(all_of(names(Experiment1)))  # Ensure same columns as Experiment1
# Combine both experiments
df_combined <- bind_rows(Experiment1, Experiment2)
# Check final dataset structure
glimpse(df_combined)
# View first rows to confirm changes
head(df_combined)
# Combine both experiments
df_combined <- bind_rows(Experiment1, Experiment2)
# Split Participant_ID into ID and Session
df_combined <- df_combined %>%
mutate(
ID = str_extract(Participant_ID, "^[^_]+"),  # Extract part before '_'
Session = str_extract(Participant_ID, "(?<=_).*")  # Extract part after '_'
)
# Create Agent_Type and initial Agent_Effect based on Collider_Name
df_combined <- df_combined %>%
mutate(
Agent_Type = ifelse(str_detect(Collider_Name, "Cma"), "Active", "Passive"),
Agent_Effect = ifelse(Agent_Type == "Active", 0.5, -0.5)  # Initial effect coding
)
# Continue with additional effect coding and Event_Index creation
df_combined <- df_combined %>%
mutate(
# Define Match (Congruency) using the original rule
Match = ifelse((Experiment == 1 & Agent_Effect == 0.5), 0.5, -0.5),
# Effect coding for Experiment
Experiment = case_when(
Experiment == 1 ~ -0.5,
Experiment == 2 ~ 0.5,
TRUE ~ NaN
)
) %>%
arrange(ID, Session, Gaze_Time) %>%  # Chronological order
group_by(ID, Session) %>%
mutate(Event_Index = row_number()) %>%
ungroup()
# Convert new variables to factors and explicitly define Agent_Type levels (Acontextual, Congruent, Incongruent)
df_combined <- df_combined %>%
mutate(
ID = as.factor(ID),
Session = as.factor(Session),
Agent_Type = factor(case_when(
Agent_Effect == -0.5 ~ "Acontextual",
Agent_Effect == 0.5 & Experiment == -0.5 ~ "Congruent",
Agent_Effect == 0.5 & Experiment == 0.5 ~ "Incongruent",
TRUE ~ NA_character_
), levels = c("Acontextual", "Congruent", "Incongruent"))
)
# Display first few rows to verify changes
head(df_combined)
# Combine both experiments
df_combined <- bind_rows(Experiment1, Experiment2)
# Split Participant_ID into ID and Session
df_combined <- df_combined %>%
mutate(
ID = str_extract(Participant_ID, "^[^_]+"),  # Extract part before '_'
Session = str_extract(Participant_ID, "(?<=_).*")  # Extract part after '_'
)
# Create Agent_Type and initial Agent_Effect based on Collider_Name
df_combined <- df_combined %>%
mutate(
Agent_Type = ifelse(str_detect(Collider_Name, "Cma"), "Active", "Passive"),
Agent_Effect = ifelse(Agent_Type == "Active", 0.5, -0.5)  # Initial effect coding
)
# Continue with additional effect coding and Event_Index creation
df_combined <- df_combined %>%
mutate(
# Define Match (Congruency) using the original rule
Match = ifelse((Experiment == 1 & Agent_Effect == 0.5), 0.5, -0.5),
# Effect coding for Experiment
Experiment = case_when(
Experiment == 1 ~ -0.5,
Experiment == 2 ~ 0.5,
TRUE ~ NaN
)
) %>%
arrange(ID, Session, Gaze_Time) %>%  # Chronological order
group_by(ID, Session) %>%
mutate(Event_Index = row_number()) %>%
ungroup()
# Convert new variables to factors and explicitly define Agent_Type levels (Acontextual, Congruent, Incongruent)
df_combined <- df_combined %>%
mutate(
ID = as.factor(ID),
Session = as.factor(Session),
Agent_Type = factor(case_when(
Agent_Effect == -0.5 ~ "Acontextual",
Agent_Effect == 0.5 & Experiment == -0.5 ~ "Congruent",
Agent_Effect == 0.5 & Experiment == 0.5 ~ "Incongruent",
TRUE ~ NA_character_
), levels = c("Acontextual", "Congruent", "Incongruent"))
)
# Display first few rows to verify changes
head(df_combined)
# Create two subsets
df_above_60 <- df_combined %>% filter(Event_Index > 60)
df_below_60 <- df_combined %>% filter(Event_Index <= 60)
# Total number of rows
total_rows <- nrow(df_combined)
# Number of rows in each category
above_60 <- nrow(df_above_60)
below_60 <- nrow(df_below_60)
# Calculate percentages
above_60_pct <- (above_60 / total_rows) * 100
below_60_pct <- (below_60 / total_rows) * 100
# Print results
cat("Percentage of Event_Index > 60:", round(above_60_pct, 2), "%\n")
cat("Percentage of Event_Index ≤ 60:", round(below_60_pct, 2), "%\n")
# Check dimensions of the kept dataframes
dim(df_above_60)  # Shows dimensions of rows and columns
dim(df_below_60)  # Shows dimensions of rows and columns
# --- Prep (as you already have) ---
df_long <- df_below_60 %>%
tidyr::pivot_longer(
cols = c(Pre_Entropy, Post_Entropy),
names_to = "Pre_Post",
values_to = "Entropy"
) %>%
mutate(
Pre_Post = factor(Pre_Post, levels = c("Pre_Entropy","Post_Entropy")),
Pre_Post_num = ifelse(Pre_Post == "Pre_Entropy", 0, 1),
ID = factor(ID),
Session = factor(Session)
)
# Smithson–Verkuilen map to (0,1)
n_eff <- sum(!is.na(df_long$Entropy))
df_long <- df_long %>%
mutate(
Entropy_raw = Entropy,
Entropy = pmin(pmax(Entropy, 0), 1),
Entropy = (Entropy * (n_eff - 1) + 0.5) / n_eff,
Event_Index_s = as.numeric(scale(Event_Index))
)
# --- Priors (weakly-informative; consistent with your write-up) ---
priors <- c(
set_prior("normal(0, 1)",          class = "b"),          # population-level (includes Intercept)
set_prior("student_t(3, 0, 2.5)",  class = "sd"),         # group-level SDs
set_prior("student_t(3, 0, 0.8)",  class = "sds"),        # smooth-term SDs
set_prior("gamma(0.01, 0.01)",     class = "phi")         # Beta precision (identity)
)
# replace Pre_Post_num by centered P_c in the formula—interpretation unchanged after back-transform
df_long <- df_long %>% mutate(P_c = Pre_Post_num - 0.5)
# --- Fit: Beta(logit) with nested RE and spline ---
bayesian_time_model <- brm(
Entropy ~ Pre_Post_num + s(Event_Index_s, k = 5) + (1 | ID) + (1 | ID:Session),
data   = df_long,
family = Beta(link = "logit"),
prior  = priors,
chains = 4, iter = 6000, warmup = 2000, cores = 4,
control = list(adapt_delta = 0.995, max_treedepth = 15),
init    = 0,
save_pars = save_pars(all = TRUE)
)
# Load necessary libraries
library(CausalImpact)  # For causal inference and impact analysis
library(dplyr)         # Data manipulation
library(ggplot2)       # Visualization
library(readr)         # Reading CSV files
library(lubridate)     # Working with dates and timestamps
library(zoo)           # Required for time-series data
library(tidyverse)     # Meta-package (includes dplyr, ggplot2, tidyr, etc.)
library(tidyr)         # Data tidying functions
library(brms)          # Bayesian regression modeling via Stan
library(stringr)       # String manipulation (used for ID extraction)
# Define directories for each experiment
exp1_dir <- "/Volumes/TwoTeras/0_Experiment_1/Entropy_Results/Window/entropy_results/CausalImpact/"
exp2_dir <- "/Volumes/TwoTeras/1_Experiment_2/Entropy_Results/Window/entropy_results/CausalImpact/"
labels <- read.csv("/Volumes/TwoTeras/Resources/AgentCoordinates_short_exp2.csv")
# List all CSV files in each directory
exp1_files <- list.files(exp1_dir, pattern = "*.csv", full.names = TRUE)
exp2_files <- list.files(exp2_dir, pattern = "*.csv", full.names = TRUE)
# Function to extract first two digits from Collider_Name
extract_first_two_digits <- function(name) {
num <- str_extract(name, "^\\d{2}")  # Extract first two digits
as.numeric(num)  # Convert to numeric
}
# Load and process Experiment 1
exp1_list <- lapply(exp1_files, read_csv)
Experiment1 <- bind_rows(exp1_list) %>%
mutate(Experiment = 1,
Collider_Number = extract_first_two_digits(Collider_Name),  # Extract first two digits
Building = ifelse(Collider_Number <= 28, "Public", "Residential"),  # Assign 'Building'
Building_Effect = ifelse(Building == "Public", 0.5, -0.5))  # Apply effect coding
# Ensure Collider_Number exists before removing it
if ("Collider_Number" %in% colnames(Experiment1)) {
Experiment1 <- Experiment1 %>% dplyr::select(-Collider_Number)
}
# Load and process Experiment 2
exp2_list <- lapply(exp2_files, read_csv)
Experiment2 <- bind_rows(exp2_list) %>%
mutate(Experiment = 2,
Collider_Number = extract_first_two_digits(Collider_Name)) %>%
left_join(labels, by = c("Collider_Name" = "AvatarName")) %>%  # Match agent names
mutate(Building = ifelse(Context == TRUE, "Public", "Residential"),
Building_Effect = ifelse(Building == "Public", 0.5, -0.5)) %>%  # Apply effect coding
dplyr::select(all_of(names(Experiment1)))  # Ensure same columns as Experiment1
# Combine both experiments
df_combined <- bind_rows(Experiment1, Experiment2)
# Check final dataset structure
glimpse(df_combined)
# View first rows to confirm changes
head(df_combined)
# Combine both experiments
df_combined <- bind_rows(Experiment1, Experiment2)
# Split Participant_ID into ID and Session
df_combined <- df_combined %>%
mutate(
ID = str_extract(Participant_ID, "^[^_]+"),  # Extract part before '_'
Session = str_extract(Participant_ID, "(?<=_).*")  # Extract part after '_'
)
# Create Agent_Type and initial Agent_Effect based on Collider_Name
df_combined <- df_combined %>%
mutate(
Agent_Type = ifelse(str_detect(Collider_Name, "Cma"), "Active", "Passive"),
Agent_Effect = ifelse(Agent_Type == "Active", 0.5, -0.5)  # Initial effect coding
)
# Continue with additional effect coding and Event_Index creation
df_combined <- df_combined %>%
mutate(
# Define Match (Congruency) using the original rule
Match = ifelse((Experiment == 1 & Agent_Effect == 0.5), 0.5, -0.5),
# Effect coding for Experiment
Experiment = case_when(
Experiment == 1 ~ -0.5,
Experiment == 2 ~ 0.5,
TRUE ~ NaN
)
) %>%
arrange(ID, Session, Gaze_Time) %>%  # Chronological order
group_by(ID, Session) %>%
mutate(Event_Index = row_number()) %>%
ungroup()
# Convert new variables to factors and explicitly define Agent_Type levels (Acontextual, Congruent, Incongruent)
df_combined <- df_combined %>%
mutate(
ID = as.factor(ID),
Session = as.factor(Session),
Agent_Type = factor(case_when(
Agent_Effect == -0.5 ~ "Acontextual",
Agent_Effect == 0.5 & Experiment == -0.5 ~ "Congruent",
Agent_Effect == 0.5 & Experiment == 0.5 ~ "Incongruent",
TRUE ~ NA_character_
), levels = c("Acontextual", "Congruent", "Incongruent"))
)
# Display first few rows to verify changes
head(df_combined)
# Create two subsets
df_above_60 <- df_combined %>% filter(Event_Index > 60)
df_below_60 <- df_combined %>% filter(Event_Index <= 60)
# Total number of rows
total_rows <- nrow(df_combined)
# Number of rows in each category
above_60 <- nrow(df_above_60)
below_60 <- nrow(df_below_60)
# Calculate percentages
above_60_pct <- (above_60 / total_rows) * 100
below_60_pct <- (below_60 / total_rows) * 100
# Print results
cat("Percentage of Event_Index > 60:", round(above_60_pct, 2), "%\n")
cat("Percentage of Event_Index ≤ 60:", round(below_60_pct, 2), "%\n")
# Check dimensions of the kept dataframes
dim(df_above_60)  # Shows dimensions of rows and columns
dim(df_below_60)  # Shows dimensions of rows and columns
# --- Prep (as you already have) ---
df_long <- df_below_60 %>%
tidyr::pivot_longer(
cols = c(Pre_Entropy, Post_Entropy),
names_to = "Pre_Post",
values_to = "Entropy"
) %>%
mutate(
Pre_Post = factor(Pre_Post, levels = c("Pre_Entropy","Post_Entropy")),
Pre_Post_num = ifelse(Pre_Post == "Pre_Entropy", 0, 1),
ID = factor(ID),
Session = factor(Session)
)
# Smithson–Verkuilen map to (0,1)
n_eff <- sum(!is.na(df_long$Entropy))
df_long <- df_long %>%
mutate(
Entropy_raw = Entropy,
Entropy = pmin(pmax(Entropy, 0), 1),
Entropy = (Entropy * (n_eff - 1) + 0.5) / n_eff,
Event_Index_s = as.numeric(scale(Event_Index))
)
# --- Priors (weakly-informative; consistent with your write-up) ---
priors <- c(
set_prior("normal(0, 1)",          class = "b"),          # population-level (includes Intercept)
set_prior("student_t(3, 0, 2.5)",  class = "sd"),         # group-level SDs
set_prior("student_t(3, 0, 0.8)",  class = "sds"),        # smooth-term SDs
set_prior("gamma(0.01, 0.01)",     class = "phi")         # Beta precision (identity)
)
# replace Pre_Post_num by centered P_c in the formula—interpretation unchanged after back-transform
df_long <- df_long %>% mutate(P_c = Pre_Post_num - 0.5)
# --- Fit: Beta(logit) with nested RE and spline ---
bayesian_time_model <- brm(
Entropy ~ Pre_Post_num + s(Event_Index_s, k = 5) + (1 | ID) + (1 | ID:Session),
data   = df_long,
family = Beta(link = "logit"),
prior  = priors,
chains = 4, iter = 6000, warmup = 2000, cores = 4,
control = list(adapt_delta = 0.995, max_treedepth = 15),
init    = 0,
save_pars = save_pars(all = TRUE)
)
